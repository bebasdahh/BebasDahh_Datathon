{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12419216,"sourceType":"datasetVersion","datasetId":7779164}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers torch sentence-transformers scikit-learn pandas lightgbm mlflow matplotlib seaborn catboost timm Pillow torchvision","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T16:02:53.741751Z","iopub.execute_input":"2025-07-10T16:02:53.742010Z","iopub.status.idle":"2025-07-10T16:04:16.665572Z","shell.execute_reply.started":"2025-07-10T16:02:53.741989Z","shell.execute_reply":"2025-07-10T16:04:16.664685Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (4.6.0)\nCollecting mlflow\n  Downloading mlflow-3.1.1-py3-none-any.whl.metadata (29 kB)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.2)\nRequirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.12.2)\nRequirement already satisfied: catboost in /usr/local/lib/python3.11/dist-packages (1.2.8)\nRequirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.15)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nCollecting mlflow-skinny==3.1.1 (from mlflow)\n  Downloading mlflow_skinny-3.1.1-py3-none-any.whl.metadata (30 kB)\nRequirement already satisfied: Flask<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.0)\nRequirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.15.2)\nRequirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (7.1.0)\nCollecting graphene<4 (from mlflow)\n  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\nCollecting gunicorn<24 (from mlflow)\n  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\nRequirement already satisfied: pyarrow<21,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (19.0.1)\nRequirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.40)\nRequirement already satisfied: cachetools<7,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (5.5.2)\nRequirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (8.1.8)\nRequirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (3.1.1)\nCollecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.1.1->mlflow)\n  Downloading databricks_sdk-0.58.0-py3-none-any.whl.metadata (39 kB)\nCollecting fastapi<1 (from mlflow-skinny==3.1.1->mlflow)\n  Downloading fastapi-0.116.0-py3-none-any.whl.metadata (28 kB)\nRequirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (3.1.44)\nRequirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (8.7.0)\nRequirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (1.31.1)\nRequirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (1.31.1)\nRequirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (3.20.3)\nRequirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (2.11.4)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (0.5.3)\nCollecting uvicorn<1 (from mlflow-skinny==3.1.1->mlflow)\n  Downloading uvicorn-0.35.0-py3-none-any.whl.metadata (6.5 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.0.9)\nRequirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\nRequirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\nRequirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\nRequirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.3.10)\nRequirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker<8,>=4.0.0->mlflow) (2.4.0)\nRequirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.1.3)\nRequirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (2.2.0)\nRequirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (1.9.0)\nCollecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\nCollecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\nRequirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.1.2)\nRequirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.11/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow) (2.40.1)\nCollecting starlette<0.47.0,>=0.40.0 (from fastapi<1->mlflow-skinny==3.1.1->mlflow)\n  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.1.1->mlflow) (4.0.12)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.1.1->mlflow) (3.21.0)\nRequirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==3.1.1->mlflow) (1.2.18)\nCollecting importlib_metadata!=4.7.0,<9,>=3.7.0 (from mlflow-skinny==3.1.1->mlflow)\n  Downloading importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.52b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.1.1->mlflow) (0.52b1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow) (0.4.0)\nRequirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn<1->mlflow-skinny==3.1.1->mlflow) (0.14.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==3.1.1->mlflow) (1.17.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.1.1->mlflow) (5.0.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow) (4.9.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==3.1.1->mlflow) (4.9.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==3.1.1->mlflow) (1.3.1)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow) (0.6.1)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading mlflow-3.1.1-py3-none-any.whl (24.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.7/24.7 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading mlflow_skinny-3.1.1-py3-none-any.whl (1.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading databricks_sdk-0.58.0-py3-none-any.whl (741 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m741.4/741.4 kB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fastapi-0.116.0-py3-none-any.whl (95 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.6/95.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\nDownloading importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\nDownloading uvicorn-0.35.0-py3-none-any.whl (66 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading starlette-0.46.2-py3-none-any.whl (72 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: uvicorn, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, importlib_metadata, gunicorn, graphql-core, starlette, nvidia-cusparse-cu12, nvidia-cudnn-cu12, graphql-relay, nvidia-cusolver-cu12, graphene, fastapi, databricks-sdk, mlflow-skinny, mlflow\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: importlib_metadata\n    Found existing installation: importlib_metadata 8.7.0\n    Uninstalling importlib_metadata-8.7.0:\n      Successfully uninstalled importlib_metadata-8.7.0\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed databricks-sdk-0.58.0 fastapi-0.116.0 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 gunicorn-23.0.0 importlib_metadata-8.6.1 mlflow-3.1.1 mlflow-skinny-3.1.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 starlette-0.46.2 uvicorn-0.35.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install --upgrade sentence-transformers transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T16:06:31.617822Z","iopub.execute_input":"2025-07-10T16:06:31.618678Z","iopub.status.idle":"2025-07-10T16:06:43.949001Z","shell.execute_reply.started":"2025-07-10T16:06:31.618644Z","shell.execute_reply":"2025-07-10T16:06:43.948311Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\nCollecting sentence-transformers\n  Downloading sentence_transformers-5.0.0-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\nCollecting transformers\n  Downloading transformers-4.53.1-py3-none-any.whl.metadata (40 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.2)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.31.1)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\nRequirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.13.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading sentence_transformers-5.0.0-py3-none-any.whl (470 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m470.2/470.2 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading transformers-4.53.1-py3-none-any.whl (10.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: transformers, sentence-transformers\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.51.3\n    Uninstalling transformers-4.51.3:\n      Successfully uninstalled transformers-4.51.3\n  Attempting uninstall: sentence-transformers\n    Found existing installation: sentence-transformers 3.4.1\n    Uninstalling sentence-transformers-3.4.1:\n      Successfully uninstalled sentence-transformers-3.4.1\nSuccessfully installed sentence-transformers-5.0.0 transformers-4.53.1\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip freeze","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T16:08:29.466301Z","iopub.execute_input":"2025-07-10T16:08:29.466611Z","iopub.status.idle":"2025-07-10T16:08:31.148717Z","shell.execute_reply.started":"2025-07-10T16:08:29.466583Z","shell.execute_reply":"2025-07-10T16:08:31.147508Z"}},"outputs":[{"name":"stdout","text":"absl-py==1.4.0\naccelerate==1.5.2\naiofiles==22.1.0\naiohappyeyeballs==2.6.1\naiohttp==3.11.18\naiosignal==1.3.2\naiosqlite==0.21.0\nalabaster==1.0.0\nalbucore==0.0.23\nalbumentations==2.0.5\nale-py==0.10.2\nalembic==1.15.2\naltair==5.5.0\nannotated-types==0.7.0\nannoy==1.17.3\nansicolors==1.1.8\nantlr4-python3-runtime==4.9.3\nanyio==4.9.0\nargon2-cffi==23.1.0\nargon2-cffi-bindings==21.2.0\nargs==0.1.0\narray_record==0.7.1\narrow==1.3.0\narviz==0.21.0\nastropy==7.0.1\nastropy-iers-data==0.2025.3.31.0.36.18\nasttokens==3.0.0\nastunparse==1.6.3\natpublic==5.1\nattrs==25.3.0\naudioread==3.0.1\nautograd==1.7.0\nbabel==2.17.0\nbackcall==0.2.0\nbayesian-optimization==2.0.3\nbeartype==0.20.2\nbeautifulsoup4==4.13.3\nbetterproto==2.0.0b6\nbigframes==1.42.0\nbigquery-magics==0.9.0\nbleach==6.2.0\nblinker==1.9.0\nblis==1.2.1\nblobfile==3.0.0\nblosc2==3.2.1\nbokeh==3.6.3\nBoruta==0.4.3\nboto3==1.38.11\nbotocore==1.38.11\nBottleneck==1.4.2\n-e git+https://github.com/SohierDane/BigQuery_Helper@8615a7f6c1663e7f2d48aa2b32c2dbcb600a440f#egg=bq_helper\nbqplot==0.12.44\nbranca==0.8.1\nCacheControl==0.14.2\ncachetools==5.5.2\nCartopy==0.24.1\ncatalogue==2.0.10\ncatboost==1.2.8\ncategory_encoders==2.7.0\ncertifi==2025.4.26\ncesium==0.12.4\ncffi==1.17.1\nchardet==5.2.0\ncharset-normalizer==3.4.2\nChessnut==0.4.1\nchex==0.1.89\nclarabel==0.10.0\nclick==8.1.8\nclick-plugins==1.1.1\ncligj==0.7.2\nclint==0.5.1\ncloudpathlib==0.21.0\ncloudpickle==3.1.1\ncmake==3.31.6\ncmdstanpy==1.2.5\ncolorama==0.4.6\ncolorcet==3.1.0\ncolorlog==6.9.0\ncolorlover==0.3.0\ncolour==0.1.5\ncomm==0.2.2\ncommunity==1.0.0b1\nconfection==0.1.5\ncons==0.4.6\ncontourpy==1.3.1\ncoverage==7.8.0\ncramjam==2.9.1\ncryptography==44.0.3\ncuda-bindings==12.9.0\ncuda-python==12.9.0\ncudf-cu12==25.2.2\ncudf-polars-cu12==25.2.2\ncufflinks==0.17.3\ncuml-cu12==25.2.1\ncupy-cuda12x==13.4.1\ncuvs-cu12==25.2.1\ncvxopt==1.3.2\ncvxpy==1.6.4\ncycler==0.12.1\ncyipopt==1.5.0\ncymem==2.0.11\nCython==3.0.12\ncytoolz==1.0.1\ndaal==2025.5.0\ndacite==1.9.2\ndask==2024.12.1\ndask-cuda==25.2.0\ndask-cudf-cu12==25.2.2\ndask-expr==1.1.21\ndatabricks-sdk==0.58.0\ndataclasses-json==0.6.7\ndatascience==0.17.6\ndatasets==3.6.0\ndb-dtypes==1.4.2\ndbus-python==1.2.18\ndeap==1.4.3\ndebugpy==1.8.0\ndecorator==4.4.2\ndeepdiff==8.4.2\ndefusedxml==0.7.1\nDeprecated==1.2.18\ndiffusers==0.32.2\ndill==0.3.8\ndipy==1.11.0\ndistributed==2024.12.1\ndistributed-ucxx-cu12==0.42.0\ndistro==1.9.0\ndlib==19.24.6\ndm-tree==0.1.9\ndnspython==2.7.0\ndocker==7.1.0\ndocker-pycreds==0.4.0\ndocstring-to-markdown==0.17\ndocstring_parser==0.16\ndocutils==0.21.2\ndopamine_rl==4.1.2\nduckdb==1.2.1\nearthengine-api==1.5.9\neasydict==1.13\neasyocr==1.7.2\neditdistance==0.8.1\neerepr==0.1.1\neinops==0.8.1\neli5==0.13.0\nemail_validator==2.2.0\nemoji==2.14.1\nen_core_web_sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl#sha256=1932429db727d4bff3deed6b34cfc05df17794f4a52eeb26cf8928f7c1a0fb85\nentrypoints==0.4\net_xmlfile==2.0.0\netils==1.12.2\netuples==0.3.9\nexecnb==0.1.14\nFarama-Notifications==0.0.4\nfastai==2.7.19\nfastapi==0.116.0\nfastcore==1.7.29\nfastdownload==0.0.7\nfastjsonschema==2.21.1\nfastprogress==1.0.3\nfastrlock==0.8.3\nfasttext==0.9.3\nfeaturetools==1.31.0\nfilelock==3.18.0\nfiona==1.10.1\nfirebase-admin==6.7.0\nFlask==3.1.0\nflatbuffers==25.2.10\nflax==0.10.5\nfolium==0.19.5\nfonttools==4.57.0\nfqdn==1.5.1\nfrozendict==2.4.6\nfrozenlist==1.6.0\nfsspec==2025.3.2\nfuncy==2.0\nfury==0.12.0\nfuture==1.0.0\nfuzzywuzzy==0.18.0\ngast==0.6.0\ngatspy==0.3\ngcsfs==2025.3.2\nGDAL==3.6.4\ngdown==5.2.0\ngeemap==0.35.3\ngensim==4.3.3\ngeocoder==1.38.1\ngeographiclib==2.0\ngeojson==3.2.0\ngeopandas==0.14.4\ngeopy==2.4.1\nghapi==1.0.6\ngin-config==0.5.0\ngitdb==4.0.12\nGitPython==3.1.44\nglob2==0.7\ngoogle==2.0.3\ngoogle-ai-generativelanguage==0.6.15\ngoogle-api-core==1.34.1\ngoogle-api-python-client==2.164.0\ngoogle-auth==2.40.1\ngoogle-auth-httplib2==0.2.0\ngoogle-auth-oauthlib==1.2.1\ngoogle-cloud-aiplatform==1.87.0\ngoogle-cloud-automl==1.0.1\ngoogle-cloud-bigquery==3.25.0\ngoogle-cloud-bigquery-connection==1.18.2\ngoogle-cloud-bigtable==2.30.0\ngoogle-cloud-core==2.4.3\ngoogle-cloud-dataproc==5.18.1\ngoogle-cloud-datastore==2.20.2\ngoogle-cloud-firestore==2.20.1\ngoogle-cloud-functions==1.20.2\ngoogle-cloud-iam==2.18.3\ngoogle-cloud-language==2.17.1\ngoogle-cloud-pubsub==2.29.0\ngoogle-cloud-resource-manager==1.14.2\ngoogle-cloud-spanner==3.53.0\ngoogle-cloud-storage==2.19.0\ngoogle-cloud-translate==3.12.1\ngoogle-cloud-videointelligence==2.16.1\ngoogle-cloud-vision==3.10.1\ngoogle-colab @ file:///colabtools/dist/google_colab-1.0.0.tar.gz\ngoogle-crc32c==1.7.1\ngoogle-genai==1.9.0\ngoogle-generativeai==0.8.4\ngoogle-pasta==0.2.0\ngoogle-resumable-media==2.7.2\ngoogle-spark-connect==0.5.2\ngoogleapis-common-protos==1.70.0\ngoogledrivedownloader==1.1.0\ngpxpy==1.6.2\ngraphene==3.4.3\ngraphql-core==3.2.6\ngraphql-relay==3.2.0\ngraphviz==0.20.3\ngreenlet==3.1.1\ngrpc-google-iam-v1==0.14.2\ngrpc-interceptor==0.15.4\ngrpcio==1.72.0rc1\ngrpcio-status==1.49.0rc1\ngrpclib==0.4.8\ngspread==6.2.0\ngspread-dataframe==4.0.0\ngunicorn==23.0.0\ngym==0.25.2\ngym-notices==0.0.8\ngymnasium==0.29.0\nh11==0.14.0\nh2==4.2.0\nh2o==3.46.0.7\nh5netcdf==1.6.1\nh5py==3.13.0\nhaversine==2.9.0\nhdbscan==0.8.40\nhep_ml==0.7.3\nhf-xet==1.1.0\nhf_transfer==0.1.9\nhighspy==1.9.0\nholidays==0.69\nholoviews==1.20.2\nhpack==4.1.0\nhtml5lib==1.1\nhtmlmin==0.1.12\nhttpcore==1.0.7\nhttpimport==1.4.1\nhttplib2==0.22.0\nhttpx==0.28.1\nhuggingface-hub==0.31.1\nhumanize==4.12.2\nhyperframe==6.1.0\nhyperopt==0.2.7\nibis-framework==9.5.0\nid==1.5.0\nidna==3.10\nigraph==0.11.8\nImageHash==4.3.1\nimageio==2.37.0\nimageio-ffmpeg==0.6.0\nimagesize==1.4.1\nimbalanced-learn==0.13.0\nimmutabledict==4.2.1\nimportlib_metadata==8.6.1\nimportlib_resources==6.5.2\nimutils==0.5.4\nin-toto-attestation==0.9.3\ninflect==7.5.0\niniconfig==2.1.0\nintel-cmplr-lib-rt==2024.2.0\nintel-cmplr-lib-ur==2024.2.0\nintel-openmp==2024.2.0\nipyevents==2.0.2\nipyfilechooser==0.6.0\nipykernel==6.17.1\nipyleaflet==0.19.2\nipympl==0.9.7\nipyparallel==8.8.0\nipython==7.34.0\nipython-genutils==0.2.0\nipython-sql==0.5.0\nipytree==0.2.2\nipywidgets==8.1.5\nisoduration==20.11.0\nisoweek==1.3.3\nitsdangerous==2.2.0\nJanome==0.5.0\njax==0.5.2\njax-cuda12-pjrt==0.5.1\njax-cuda12-plugin==0.5.1\njaxlib==0.5.1\njedi==0.19.2\njeepney==0.7.1\njellyfish==1.1.0\njieba==0.42.1\nJinja2==3.1.6\njiter==0.9.0\njmespath==1.0.1\njoblib==1.5.0\njson5==0.12.0\njsonpatch==1.33\njsonpickle==4.0.5\njsonpointer==3.0.0\njsonschema==4.23.0\njsonschema-specifications==2024.10.1\njupyter-console==6.1.0\njupyter-events==0.12.0\njupyter-leaflet==0.19.2\njupyter-lsp==1.5.1\njupyter-ydoc==0.2.5\njupyter_client==8.6.3\njupyter_core==5.7.2\njupyter_server==2.12.5\njupyter_server_fileid==0.9.3\njupyter_server_terminals==0.5.3\njupyter_server_ydoc==0.8.0\njupyterlab==3.6.8\njupyterlab-lsp==3.10.2\njupyterlab_pygments==0.3.0\njupyterlab_server==2.27.3\njupyterlab_widgets==3.0.13\nkaggle==1.7.4.2\nkaggle-environments==1.16.11\nkagglehub==0.3.12\nkeras==3.8.0\nkeras-core==0.1.7\nkeras-cv==0.9.0\nkeras-hub==0.18.1\nkeras-nlp==0.18.1\nkeras-tuner==1.4.7\nkeyring==23.5.0\nkiwisolver==1.4.8\nkornia==0.8.1\nkornia_rs==0.1.9\nkt-legacy==1.0.5\nlangchain==0.3.22\nlangchain-core==0.3.50\nlangchain-text-splitters==0.3.7\nlangcodes==3.5.0\nlangid==1.1.6\nlangsmith==0.3.23\nlanguage_data==1.3.0\nlaunchpadlib==1.10.16\nlazr.restfulclient==0.14.4\nlazr.uri==1.0.6\nlazy_loader==0.4\nlearntools @ git+https://github.com/Kaggle/learntools@9188cafa2795c2cb720981631280853a7e55649c\nlibclang==18.1.1\nlibcudf-cu12==25.2.2\nlibcugraph-cu12==25.2.0\nlibcuml-cu12==25.2.1\nlibcuvs-cu12==25.2.1\nlibkvikio-cu12==25.2.1\nlibpysal==4.9.2\nlibraft-cu12==25.2.0\nlibrosa==0.11.0\nlibucx-cu12==1.18.1\nlibucxx-cu12==0.42.0\nlightgbm @ file:///tmp/lightgbm/lightgbm-4.6.0-py3-none-linux_x86_64.whl\nlightning-utilities==0.14.3\nlime==0.2.0.1\nline_profiler==4.2.0\nlinkify-it-py==2.0.3\nllvmlite==0.43.0\nlml==0.2.0\nlocket==1.0.0\nlogical-unification==0.4.6\nlxml==5.3.1\nMako==1.3.10\nmamba==0.11.3\nmarisa-trie==1.2.1\nMarkdown==3.7\nmarkdown-it-py==3.0.0\nMarkupSafe==3.0.2\nmarshmallow==3.26.1\nmatplotlib==3.7.2\nmatplotlib-inline==0.1.7\nmatplotlib-venn==1.1.2\nmdit-py-plugins==0.4.2\nmdurl==0.1.2\nminiKanren==1.0.3\nmissingno==0.5.2\nmistune==0.8.4\nmizani==0.13.2\nmkl==2025.1.0\nmkl-fft==1.3.8\nmkl-random==1.2.4\nmkl-service==2.4.1\nmkl-umath==0.1.1\nml-dtypes==0.4.1\nmlcrate==0.2.0\nmlflow==3.1.1\nmlflow-skinny==3.1.1\nmlxtend==0.23.4\nmne==1.9.0\nmodel-signing==1.0.1\nmore-itertools==10.6.0\nmoviepy==1.0.3\nmpld3==0.5.10\nmpmath==1.3.0\nmsgpack==1.1.0\nmultidict==6.4.3\nmultimethod==1.12\nmultipledispatch==1.0.0\nmultiprocess==0.70.16\nmultitasking==0.0.11\nmurmurhash==1.0.12\nmusic21==9.3.0\nmypy_extensions==1.1.0\nnamex==0.0.8\nnarwhals==1.33.0\nnatsort==8.4.0\nnbclassic==1.2.0\nnbclient==0.5.13\nnbconvert==6.4.5\nnbdev==2.3.36\nnbformat==5.10.4\nndindex==1.9.2\nnest-asyncio==1.6.0\nnetworkx==3.4.2\nnibabel==5.3.2\nnilearn==0.10.4\nninja==1.11.1.4\nnltk==3.9.1\nnotebook==6.5.4\nnotebook_shim==0.2.4\nnumba==0.60.0\nnumba-cuda==0.2.0\nnumexpr==2.10.2\nnumpy==1.26.4\nnvidia-cublas-cu12==12.4.5.8\nnvidia-cuda-cupti-cu12==12.4.127\nnvidia-cuda-nvcc-cu12==12.5.82\nnvidia-cuda-nvrtc-cu12==12.4.127\nnvidia-cuda-runtime-cu12==12.4.127\nnvidia-cudnn-cu12==9.1.0.70\nnvidia-cufft-cu12==11.2.1.3\nnvidia-curand-cu12==10.3.5.147\nnvidia-cusolver-cu12==11.6.1.9\nnvidia-cusparse-cu12==12.3.1.170\nnvidia-cusparselt-cu12==0.6.2\nnvidia-ml-py==12.575.51\nnvidia-nccl-cu12==2.21.5\nnvidia-nvcomp-cu12==4.2.0.11\nnvidia-nvjitlink-cu12==12.4.127\nnvidia-nvtx-cu12==12.4.127\nnvtx==0.2.11\nnx-cugraph-cu12 @ https://pypi.nvidia.com/nx-cugraph-cu12/nx_cugraph_cu12-25.2.0-py3-none-any.whl\noauth2client==4.1.3\noauthlib==3.2.2\nodfpy==1.4.1\nolefile==0.47\nomegaconf==2.3.0\nonnx==1.17.0\nopenai==1.70.0\nopencv-contrib-python==4.11.0.86\nopencv-python==4.11.0.86\nopencv-python-headless==4.11.0.86\nopenpyxl==3.1.5\nopenslide-bin==4.0.0.8\nopenslide-python==1.4.2\nopentelemetry-api==1.31.1\nopentelemetry-sdk==1.31.1\nopentelemetry-semantic-conventions==0.52b1\nopt_einsum==3.4.0\noptax==0.2.4\noptree==0.14.1\noptuna==4.3.0\norbax-checkpoint==0.11.10\norderly-set==5.4.1\norjson==3.10.16\nosqp==1.0.3\noverrides==7.7.0\npackaging==25.0\npandas==2.2.3\npandas-datareader==0.10.0\npandas-gbq==0.28.0\npandas-profiling==3.6.6\npandas-stubs==2.2.2.240909\npandasql==0.7.3\npandocfilters==1.5.1\npanel==1.6.2\npapermill==2.6.0\nparam==2.2.0\nparso==0.8.4\nparsy==2.1\npartd==1.4.2\npath==17.1.0\npath.py==12.5.0\npathlib==1.0.1\npathos==0.3.2\npatsy==1.0.1\npdf2image==1.17.0\npeewee==3.17.9\npeft==0.14.0\npettingzoo==1.24.0\npexpect==4.9.0\nphik==0.12.4\npickleshare==0.7.5\npillow==11.1.0\nplatformdirs==4.3.8\nplotly==5.24.1\nplotly-express==0.4.1\nplotnine==0.14.5\npluggy==1.5.0\nplum-dispatch==2.5.7\nply==3.11\npolars==1.21.0\npooch==1.8.2\nportpicker==1.5.2\npox==0.3.6\nppft==1.7.7\npreprocessing==0.1.13\npreshed==3.0.9\nprettytable==3.16.0\nproglog==0.1.11\nprogressbar2==4.5.0\nprometheus_client==0.21.1\npromise==2.3\nprompt_toolkit==3.0.50\npropcache==0.3.1\nprophet==1.1.6\nproto-plus==1.26.1\nprotobuf==3.20.3\npsutil==7.0.0\npsycopg2==2.9.10\nptyprocess==0.7.0\npudb==2025.1\npuremagic==1.29\npy-cpuinfo==9.0.0\npy4j==0.10.9.7\npyaml==25.1.0\nPyArabic==0.6.15\npyarrow==19.0.1\npyasn1==0.6.1\npyasn1_modules==0.4.2\npybind11==2.13.6\npycairo==1.27.0\npyclipper==1.3.0.post6\npycocotools==2.0.8\npycparser==2.22\npycryptodome==3.22.0\npycryptodomex==3.22.0\npycuda==2025.1\npydantic==2.11.4\npydantic_core==2.33.2\npydata-google-auth==1.9.1\npydegensac==0.1.2\npydicom==3.0.1\npydot==3.0.4\npydotplus==2.0.2\nPyDrive==1.3.1\nPyDrive2==1.21.3\npydub==0.25.1\npyemd==1.0.0\npyerfa==2.0.1.5\npyexcel-io==0.6.7\npyexcel-ods==0.6.0\npygame==2.6.1\npygit2==1.17.0\npygltflib==1.16.4\nPygments==2.19.1\nPyGObject==3.42.0\nPyJWT==2.10.1\npyLDAvis==3.4.1\npylibcudf-cu12==25.2.2\npylibcugraph-cu12==25.2.0\npylibraft-cu12==25.2.0\npymc==5.21.2\npymc3==3.11.4\npymongo==4.12.1\nPympler==1.1\npymystem3==0.2.0\npynndescent==0.5.13\npynvjitlink-cu12==0.5.2\npynvml==12.0.0\npyogrio==0.10.0\nPyomo==6.8.2\nPyOpenGL==3.1.9\npyOpenSSL==25.0.0\npyparsing==3.0.9\npypdf==5.4.0\npyperclip==1.9.0\npyproj==3.7.1\npyshp==2.3.1\nPySocks==1.7.1\npyspark==3.5.5\npytensor==2.30.2\npytesseract==0.3.13\npytest==8.3.5\npython-apt==0.0.0\npython-bidi==0.6.6\npython-box==7.3.2\npython-dateutil==2.9.0.post0\npython-json-logger==3.3.0\npython-louvain==0.16\npython-lsp-jsonrpc==1.1.2\npython-lsp-server==1.12.2\npython-slugify==8.0.4\npython-snappy==0.7.3\npython-utils==3.9.1\npytools==2025.1.3\npytorch-ignite==0.5.2\npytorch-lightning==2.5.1.post0\npytz==2025.2\nPyUpSet==0.1.1.post7\npyviz_comms==3.0.4\nPyWavelets==1.8.0\nPyYAML==6.0.2\npyzmq==24.0.1\nqgrid==1.3.1\nqtconsole==5.6.1\nQtPy==2.4.3\nraft-dask-cu12==25.2.0\nrapids-dask-dependency==25.2.0\nratelim==0.1.6\nray==2.46.0\nreferencing==0.36.2\nregex==2024.11.6\nrequests==2.32.3\nrequests-oauthlib==2.0.0\nrequests-toolbelt==1.0.0\nrequirements-parser==0.9.0\nrfc3161-client==1.0.1\nrfc3339-validator==0.1.4\nrfc3986-validator==0.1.1\nrfc8785==0.1.4\nrgf-python==3.12.0\nrich==14.0.0\nrmm-cu12==25.2.0\nroman-numerals-py==3.1.0\nrpds-py==0.24.0\nrpy2==3.5.17\nrsa==4.9.1\nrtree==1.4.0\ns3fs==0.4.2\ns3transfer==0.12.0\nsafetensors==0.5.3\nscikit-image==0.25.2\nscikit-learn==1.2.2\nscikit-learn-intelex==2025.5.0\nscikit-multilearn==0.2.0\nscikit-optimize==0.10.2\nscikit-plot==0.3.7\nscikit-surprise==1.1.4\nscipy==1.15.2\nscooby==0.10.0\nscs==3.2.7.post2\nseaborn==0.12.2\nSecretStorage==3.3.1\nsecuresystemslib==1.3.0\nsegment_anything @ git+https://github.com/facebookresearch/segment-anything.git@dca509fe793f601edb92606367a655c15ac00fdf\nsemver==3.0.4\nSend2Trash==1.8.3\nsentence-transformers==5.0.0\nsentencepiece==0.2.0\nsentry-sdk==2.25.1\nsetproctitle==1.3.5\nsetuptools-scm==8.3.1\nshap==0.44.1\nshapely==2.1.0\nshellingham==1.5.4\nShimmy==1.3.0\nsigstore==3.6.2\nsigstore-protobuf-specs==0.3.2\nsigstore-rekor-types==0.0.18\nsimple-parsing==0.1.7\nsimpleitk==2.5.0\nsimplejson==3.20.1\nsimsimd==6.2.1\nsiphash24==1.7\nsix==1.17.0\nsklearn-compat==0.1.3\nsklearn-pandas==2.2.0\nslicer==0.0.7\nsmart-open==7.1.0\nsmmap==5.0.2\nsniffio==1.3.1\nsnowballstemmer==2.2.0\nsortedcontainers==2.4.0\nsoundfile==0.13.1\nsoupsieve==2.6\nsoxr==0.5.0.post1\nspacy==3.8.5\nspacy-legacy==3.0.12\nspacy-loggers==1.0.5\nspanner-graph-notebook==1.1.6\nSphinx==8.2.3\nsphinx-rtd-theme==0.2.4\nsphinxcontrib-applehelp==2.0.0\nsphinxcontrib-devhelp==2.0.0\nsphinxcontrib-htmlhelp==2.1.0\nsphinxcontrib-jsmath==1.0.1\nsphinxcontrib-qthelp==2.0.0\nsphinxcontrib-serializinghtml==2.0.0\nSQLAlchemy==2.0.40\nsqlglot==25.20.2\nsqlparse==0.5.3\nsquarify==0.4.4\nsrsly==2.5.1\nstable-baselines3==2.1.0\nstanio==0.5.1\nstarlette==0.46.2\nstatsmodels==0.14.4\nstopit==1.1.2\nstringzilla==3.12.3\nstumpy==1.13.0\nsympy==1.13.1\ntables==3.10.2\ntabulate==0.9.0\ntbb==2022.1.0\ntbb4py==2022.1.0\ntblib==3.1.0\ntcmlib==1.3.0\ntenacity==9.1.2\ntensorboard==2.18.0\ntensorboard-data-server==0.7.2\ntensorflow==2.18.0\ntensorflow-cloud==0.1.5\ntensorflow-datasets==4.9.8\ntensorflow-hub==0.16.1\ntensorflow-io==0.37.1\ntensorflow-io-gcs-filesystem==0.37.1\ntensorflow-metadata==1.17.0\ntensorflow-probability==0.25.0\ntensorflow-text==2.18.1\ntensorflow_decision_forests==1.11.0\ntensorstore==0.1.73\ntermcolor==3.0.1\nterminado==0.18.1\ntestpath==0.6.0\ntext-unidecode==1.3\ntextblob==0.19.0\ntexttable==1.7.0\ntf-slim==1.1.0\ntf_keras==2.18.0\nTheano==1.0.5\nTheano-PyMC==1.1.2\nthinc==8.3.4\nthreadpoolctl==3.6.0\ntifffile==2025.3.30\ntiktoken==0.9.0\ntimm==1.0.15\ntinycss2==1.4.0\ntokenizers==0.21.1\ntoml==0.10.2\ntoolz==1.0.0\ntorch @ https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl\ntorchao==0.10.0\ntorchaudio @ https://download.pytorch.org/whl/cu124/torchaudio-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl\ntorchdata==0.11.0\ntorchinfo==1.8.0\ntorchmetrics==1.7.1\ntorchsummary==1.5.1\ntorchtune==0.6.1\ntorchvision @ https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp311-cp311-linux_x86_64.whl\ntornado==6.4.2\nTPOT==0.12.1\ntqdm==4.67.1\ntraitlets==5.7.1\ntraittypes==0.2.1\ntransformers==4.53.1\ntreelite==4.4.1\ntreescope==0.1.9\ntriton==3.2.0\ntrx-python==0.3\ntsfresh==0.21.0\ntuf==6.0.0\ntweepy==4.15.0\ntypeguard==4.4.2\ntyper==0.15.2\ntypes-python-dateutil==2.9.0.20241206\ntypes-pytz==2025.2.0.20250326\ntypes-setuptools==78.1.0.20250329\ntyping-inspect==0.9.0\ntyping-inspection==0.4.0\ntyping_extensions==4.13.2\ntzdata==2025.2\ntzlocal==5.3.1\nuc-micro-py==1.0.3\nucx-py-cu12==0.42.0\nucxx-cu12==0.42.0\nujson==5.10.0\numap-learn==0.5.7\numf==0.10.0\nupdate-checker==0.18.0\nuri-template==1.3.0\nuritemplate==4.1.1\nurllib3==2.4.0\nurwid==3.0.2\nurwid_readline==0.15.1\nuvicorn==0.35.0\nvega-datasets==0.9.0\nvisions==0.8.1\nvtk==9.3.1\nwadllib==1.3.6\nWand==0.6.13\nwandb==0.19.9\nwasabi==1.1.3\nwatchdog==6.0.0\nwavio==0.0.9\nwcwidth==0.2.13\nweasel==0.4.1\nwebcolors==24.11.1\nwebencodings==0.5.1\nwebsocket-client==1.8.0\nwebsockets==15.0.1\nWerkzeug==3.1.3\nwidgetsnbextension==4.0.14\nwoodwork==0.31.0\nwordcloud==1.9.4\nwrapt==1.17.2\nwurlitzer==3.1.1\nxarray==2025.1.2\nxarray-einstats==0.8.0\nxgboost==2.0.3\nxlrd==2.0.1\nxvfbwrapper==0.2.13\nxxhash==3.5.0\nxyzservices==2025.1.0\ny-py==0.6.2\nyarl==1.20.0\nydata-profiling==4.16.1\nydf==0.9.0\nyellowbrick==1.5\nyfinance==0.2.55\nypy-websocket==0.8.4\nzict==3.0.0\nzipp==3.21.0\nzstandard==0.23.0\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# Main Pipeline untuk raw data preprocessing (PIPELINE UNTUK DATA SEBELUM DISPLIT MENJADI TRAINING, TEST, DAN VALIDATION)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport re\nimport os\nimport numpy as np\nfrom sklearn.model_selection import GroupShuffleSplit, train_test_split\nimport gc \n\ndef prepare_final_dataset_pipeline(\n    didaftar_pdki_csv_path,\n    ditolak_pdki_csv_path,\n    didaftar_logo_csv_path,\n    ditolak_logo_csv_path,\n    output_split_dir='/kaggle/working/final_dataset_splits/'\n):\n    \"\"\"\n    Melakukan pra-pemrosesan data yang komprehensif, menggabungkan dataset,\n    mengonsolidasi baris berdasarkan Nomor Permohonan, dan melakukan grouped\n    train-validation-test split dengan penanganan khusus untuk brand 'LOGO'\n    dan menggunakan 'Brand + Nama Pemilik' sebagai kunci pengelompokan.\n\n    Args:\n        didaftar_pdki_csv_path (str): Path ke dataset_pdki_Didaftar.csv.\n        ditolak_pdki_csv_path (str): Path ke dataset_pdki_Ditolak.csv.\n        didaftar_logo_csv_path (str): Path ke dataset_logo_pdki_Didaftar.csv (dengan Logo File).\n        ditolak_logo_csv_path (str): Path ke dataset_logo_pdki_Ditolak.csv (dengan Logo File).\n        output_split_dir (str): Direktori untuk menyimpan hasil split dataset.\n\n    Returns:\n        pandas.DataFrame: DataFrame tunggal yang berisi semua data dengan kolom 'Split_Type'.\n    \"\"\"\n\n    def normalize_text_base(text):\n        \"\"\"Melakukan case folding dan menghapus spasi berlebih.\"\"\"\n        if isinstance(text, str):\n            text = text.lower()\n            text = re.sub(r'\\s+', ' ', text).strip()\n            return text\n        return text\n\n    def clean_brand_name_for_grouping_logic(brand_text):\n        \"\"\"\n        Membersihkan nama brand untuk logika split grouping:\n        - Jika persis 'logo' (case-insensitive), ganti dengan string kosong \"\".\n        - Jika mengandung 'logo' (case-insensitive) DAN ada '+' atau '&',\n          hapus 'logo' beserta tanda '+' atau '&'.\n        - Selain itu, normalisasi dasar.\n        \"\"\"\n        if not isinstance(brand_text, str):\n            return '' \n\n        original_text_lower = brand_text.lower().strip()\n\n        if original_text_lower == 'logo':\n            return ''\n\n        has_logo_substring = 'logo' in original_text_lower\n        has_punctuation = bool(re.search(r'[+&]', original_text_lower))\n\n        if has_logo_substring and has_punctuation:\n            cleaned_text = re.sub(r'\\s*[+&]*\\s*logo\\s*[+&]*\\s*', '', original_text_lower)\n            cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n            return cleaned_text\n        \n        return original_text_lower\n\n    def clean_brand_name_for_embedding_and_display(brand_text):\n        \"\"\"\n        Membersihkan nama brand untuk embedding dan display:\n        - Jika persis 'logo' (case-insensitive), ganti dengan string kosong \"\".\n        - Jika mengandung 'logo' (case-insensitive) DAN ada '+' atau '&',\n          hapus 'logo' beserta tanda '+' atau '&'.\n        - Selain itu, normalisasi dasar.\n        \"\"\"\n        if not isinstance(brand_text, str):\n            return '' \n\n        original_text_lower = brand_text.lower().strip()\n\n        if original_text_lower == 'logo':\n            return ''\n\n        has_logo_substring = 'logo' in original_text_lower\n        has_punctuation = bool(re.search(r'[+&]', original_text_lower))\n\n        if has_logo_substring and has_punctuation:\n            cleaned_text = re.sub(r'\\s*[+&]*\\s*logo\\s*[+&]*\\s*', '', original_text_lower)\n            cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n            return cleaned_text\n        \n        return original_text_lower\n\n    print(\"loading dataset awal (tanpa Logo File)...\")\n    df_didaftar_pdki = pd.read_csv(didaftar_pdki_csv_path)\n    df_ditolak_pdki = pd.read_csv(ditolak_pdki_csv_path)\n\n    df_didaftar_pdki['Logo File'] = np.nan\n    df_ditolak_pdki['Logo File'] = np.nan\n\n    initial_brand_didaftar_normalized = df_didaftar_pdki['Brand'].apply(normalize_text_base)\n    initial_brand_ditolak_normalized = df_ditolak_pdki['Brand'].apply(normalize_text_base)\n\n    df_didaftar_pdki_filtered = df_didaftar_pdki[~initial_brand_didaftar_normalized.str.contains('logo', na=False)]\n    df_ditolak_pdki_filtered = df_ditolak_pdki[~initial_brand_ditolak_normalized.str.contains('logo', na=False)]\n\n    print(f\"df_didaftar_pdki setelah filter: {len(df_didaftar_pdki_filtered)} baris\")\n    print(f\"df_ditolak_pdki setelah filter: {len(df_ditolak_pdki_filtered)} baris\")\n\n    print(\"\\nloading dataset dengan kolom 'Logo File'...\")\n    df_didaftar_logo = pd.read_csv(didaftar_logo_csv_path)\n    df_ditolak_logo = pd.read_csv(ditolak_logo_csv_path)\n\n    print(\"\\ngabungkan keempat DataFrame...\")\n    combined_df = pd.concat([\n        df_didaftar_pdki_filtered,\n        df_ditolak_pdki_filtered,\n        df_didaftar_logo,\n        df_ditolak_logo\n    ], ignore_index=True)\n    print(f\"total baris setelah penggabungan awal: {len(combined_df)}\")\n\n    print(\"\\nmelakukan pra-pemrosesan standar...\")\n    if 'No' in combined_df.columns:\n        combined_df = combined_df.drop('No', axis=1)\n\n    combined_df = combined_df.drop_duplicates(keep='first') \n\n    required_cols_for_dropna = ['Brand', 'Kode Kelas', 'Deskripsi Kelas', 'Nomor Permohonan', 'Status', 'Nama Pemilik'] \n    combined_df_cleaned = combined_df.dropna(subset=required_cols_for_dropna)\n\n    combined_df_cleaned['Deskripsi Kelas'] = combined_df_cleaned['Deskripsi Kelas'].apply(normalize_text_base)\n    \n    combined_df_cleaned['Brand'] = combined_df_cleaned['Brand'].apply(clean_brand_name_for_embedding_and_display)\n\n    combined_df_cleaned['Status_Encoded'] = combined_df_cleaned['Status'].apply(lambda x: 1 if x == 'Didaftar' else 0)\n\n    print(\"\\nkonsolidasi baris berdasarkan Nomor Permohonan...\")\n    kode_kelas_cols_before_ohe = [col for col in combined_df_cleaned.columns if col.startswith('Kode_Kelas_')]\n    \n    if kode_kelas_cols_before_ohe:\n        combined_df_cleaned = combined_df_cleaned.drop(columns=kode_kelas_cols_before_ohe)\n\n    combined_df_cleaned['Kode Kelas'] = combined_df_cleaned['Kode Kelas'].astype('category')\n    kode_kelas_one_hot = pd.get_dummies(combined_df_cleaned['Kode Kelas'], prefix='Kode_Kelas')\n    combined_df_cleaned = combined_df_cleaned.join(kode_kelas_one_hot)\n\n    agg_dict = {\n        'Tahun Permohonan': 'first',\n        'Brand': 'first',\n        'Deskripsi Kelas': lambda x: ' '.join(x.astype(str).unique()), \n        'Status_Encoded': 'first',\n        'Logo File': 'first',\n        'Nama Pemilik': 'first' \n    }\n    for col in kode_kelas_one_hot.columns:\n        agg_dict[col] = 'max'\n\n    df_consolidated = combined_df_cleaned.groupby('Nomor Permohonan').agg(agg_dict).reset_index()\n    print(f\"Total baris setelah konsolidasi Nomor Permohonan: {len(df_consolidated)}\")\n    \n \n    final_feature_cols_base = [col for col in df_consolidated.columns if col.startswith('Kode_Kelas_') or col == 'Tahun Permohonan']\n    \n    df_final_features_base = df_consolidated[final_feature_cols_base].copy()\n\n    df_final_features_base['Brand'] = df_consolidated['Brand']\n    df_final_features_base['Logo File'] = df_consolidated['Logo File']\n    df_final_features_base['Status_Encoded'] = df_consolidated['Status_Encoded']\n    df_final_features_base['Nama Pemilik'] = df_consolidated['Nama Pemilik'] \n    df_final_features_base['Nomor Permohonan'] = df_consolidated['Nomor Permohonan'] \n    df_final_features_base['Deskripsi Kelas'] = df_consolidated['Deskripsi Kelas']\n \n    df_final_features_base['Nama Pemilik_normalized'] = df_final_features_base['Nama Pemilik'].apply(\n        lambda x: str(x).lower().strip().replace(' ', '_').replace('.', '').replace(',', '') \n    )\n   \n    df_final_features_base['Brand_Owner_Group'] = df_final_features_base['Brand'] + '_' + df_final_features_base['Nama Pemilik_normalized']\n\n    print(f\"Total baris setelah konsolidasi dan pra-pemrosesan akhir: {len(df_final_features_base)}\")\n    print(\"Kolom setelah konsolidasi dan pra-pemrosesan akhir:\", df_final_features_base.columns.tolist())\n    \n    is_generic_logo_brand = (df_final_features_base['Brand'].apply(clean_brand_name_for_grouping_logic) == '') \n\n    df_generic_logo = df_final_features_base[is_generic_logo_brand]\n    df_other_brands = df_final_features_base[~is_generic_logo_brand]\n\n    print(f\"\\nJumlah baris dengan brand generik ('LOGO' dll.) untuk split: {len(df_generic_logo)}\")\n    print(f\"Jumlah baris dengan brand unik lainnya untuk split: {len(df_other_brands)}\")\n\n    print(\"\\nMelakukan Grouped Train-Validation-Test Split...\")\n    TEST_SIZE_FINAL = 0.2\n    VALIDATION_SIZE_FROM_TRAIN_VAL = 0.2\n    RANDOM_STATE = 42\n\n    groups_other = df_other_brands['Brand_Owner_Group'] \n    gss_initial_other = GroupShuffleSplit(n_splits=1, test_size=TEST_SIZE_FINAL, random_state=RANDOM_STATE)\n    train_val_idx_other, test_idx_other = next(gss_initial_other.split(df_other_brands, df_other_brands['Status_Encoded'], groups=groups_other))\n\n    df_train_val_other = df_other_brands.iloc[train_val_idx_other]\n    df_test_other = df_other_brands.iloc[test_idx_other]\n\n    gss_final_other = GroupShuffleSplit(n_splits=1, test_size=VALIDATION_SIZE_FROM_TRAIN_VAL, random_state=RANDOM_STATE)\n    groups_train_val_other_subset = df_train_val_other['Brand_Owner_Group'] \n    train_idx_final_other, val_idx_other = next(gss_final_other.split(df_train_val_other, df_train_val_other['Status_Encoded'], groups=groups_train_val_other_subset))\n\n    df_train_other = df_train_val_other.iloc[train_idx_final_other]\n    df_val_other = df_train_val_other.iloc[val_idx_other]\n\n    X_train_val_logo, X_test_logo, y_train_val_logo, y_test_logo = train_test_split(\n        df_generic_logo, df_generic_logo['Status_Encoded'], test_size=TEST_SIZE_FINAL, random_state=RANDOM_STATE, stratify=df_generic_logo['Status_Encoded']\n    )\n    df_train_logo = X_train_val_logo.copy() \n    df_train_logo['Status_Encoded'] = y_train_val_logo.copy() \n    \n    df_val_logo = X_test_logo.copy() \n    df_val_logo['Status_Encoded'] = y_test_logo.copy() \n\n    df_train = pd.concat([df_train_other, df_train_logo], ignore_index=False)\n    df_train['Split_Type'] = 'train'\n    df_train = df_train.sample(frac=1, random_state=RANDOM_STATE).reset_index(drop=True) \n\n    df_val = pd.concat([df_val_other, df_val_logo], ignore_index=False)\n    df_val['Split_Type'] = 'validation'\n    df_val = df_val.sample(frac=1, random_state=RANDOM_STATE).reset_index(drop=True) \n\n    df_test = pd.concat([df_test_other, X_test_logo], ignore_index=False) \n    df_test['Split_Type'] = 'test'\n    df_test = df_test.sample(frac=1, random_state=RANDOM_STATE).reset_index(drop=True) \n\n    print(f\"\\nfinal Shape df_train: {df_train.shape}\")\n    print(f\"final Shape df_val: {df_val.shape}\")\n    print(f\"final Shape df_test: {df_test.shape}\")\n\n    os.makedirs(output_split_dir, exist_ok=True)\n    print(f\"\\nmenyimpan split dataset ke: {output_split_dir}\")\n\n    df_train.to_csv(os.path.join(output_split_dir, 'Training_new.csv'), index=False)\n    df_val.to_csv(os.path.join(output_split_dir, 'Validation_new.csv'), index=False)\n    df_test.to_csv(os.path.join(output_split_dir, 'Test_new.csv'), index=False)\n\n    print(\"berhasil disimpan\")\n\n    final_combined_df = pd.concat([df_train, df_val, df_test], ignore_index=True)\n    final_combined_df.to_csv(os.path.join(output_split_dir, 'full_dataset_with_splits.csv'), index=True)\n    print(\"disimpan sebagai 'full_dataset_with_splits.csv'.\")\n\n \n    del combined_df, combined_df_cleaned, df_generic_logo, df_other_brands\n    del df_train_val_other, df_test_other, df_train_other, df_val_other\n    del X_train_val_logo, X_test_logo, y_train_val_logo, y_test_logo, df_train_logo, df_val_logo\n    del df_final_features_base \n    gc.collect()\n\n    return df_train, df_val, df_test\n\ntry:\n    X_train_full, X_val_full, X_test_full = prepare_final_dataset_pipeline(\n        didaftar_pdki_csv_path=\"/kaggle/input/dataset-pdki-aplikasi-merek/dataset_pdki_Didaftar.csv\",\n        ditolak_pdki_csv_path=\"/kaggle/input/dataset-pdki-aplikasi-merek/dataset_pdki_Ditolak.csv\",\n        didaftar_logo_csv_path=\"/kaggle/input/dataset-pdki-aplikasi-merek/dataset_logo_pdki_Didaftar/dataset_logo_pdki_Didaftar.csv\",\n        ditolak_logo_csv_path=\"/kaggle/input/dataset-pdki-aplikasi-merek/dataset_logo_pdki_Ditolak/dataset_logo_pdki_Ditolak.csv\"\n    )\n    print(\"\\nPipeline pra-pemrosesan dan split selesai. Dataset siap digunakan.\")\n    print(\"Final dataset with splits shape:\", X_train_full.shape)\n    print(\"Final dataset with splits shape:\", X_val_full.shape)\n    print(\"Final dataset with splits shape:\", X_test_full.shape)\nexcept Exception as e:\n    print(f\"\\nTerjadi kesalahan saat menjalankan pipeline: {e}\")\n    print(\"Pastikan semua file input ada di path yang benar dan formatnya sesuai.\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T22:49:04.214031Z","iopub.execute_input":"2025-07-08T22:49:04.214388Z","iopub.status.idle":"2025-07-08T22:50:36.484712Z","shell.execute_reply.started":"2025-07-08T22:49:04.214365Z","shell.execute_reply":"2025-07-08T22:50:36.483966Z"}},"outputs":[{"name":"stdout","text":"Memuat dataset awal (tanpa Logo File)...\ndf_didaftar_pdki setelah filter: 199270 baris\ndf_ditolak_pdki setelah filter: 82526 baris\n\nMemuat dataset dengan kolom 'Logo File'...\n\nMenggabungkan keempat DataFrame...\nTotal baris setelah penggabungan awal: 369220\n\nMelakukan pra-pemrosesan standar...\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_35/420790565.py:149: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  combined_df_cleaned['Deskripsi Kelas'] = combined_df_cleaned['Deskripsi Kelas'].apply(normalize_text_base)\n/tmp/ipykernel_35/420790565.py:152: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  combined_df_cleaned['Brand'] = combined_df_cleaned['Brand'].apply(clean_brand_name_for_embedding_and_display)\n/tmp/ipykernel_35/420790565.py:155: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  combined_df_cleaned['Status_Encoded'] = combined_df_cleaned['Status'].apply(lambda x: 1 if x == 'Didaftar' else 0)\n/tmp/ipykernel_35/420790565.py:168: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  combined_df_cleaned['Kode Kelas'] = combined_df_cleaned['Kode Kelas'].astype('category')\n","output_type":"stream"},{"name":"stdout","text":"\nMengonsolidasi baris berdasarkan Nomor Permohonan...\nTotal baris setelah konsolidasi Nomor Permohonan: 336235\nTotal baris setelah konsolidasi dan pra-pemrosesan akhir: 336235\nKolom setelah konsolidasi dan pra-pemrosesan akhir: ['Tahun Permohonan', 'Kode_Kelas_1.0', 'Kode_Kelas_2.0', 'Kode_Kelas_3.0', 'Kode_Kelas_4.0', 'Kode_Kelas_5.0', 'Kode_Kelas_6.0', 'Kode_Kelas_7.0', 'Kode_Kelas_8.0', 'Kode_Kelas_9.0', 'Kode_Kelas_10.0', 'Kode_Kelas_11.0', 'Kode_Kelas_12.0', 'Kode_Kelas_13.0', 'Kode_Kelas_14.0', 'Kode_Kelas_15.0', 'Kode_Kelas_16.0', 'Kode_Kelas_17.0', 'Kode_Kelas_18.0', 'Kode_Kelas_19.0', 'Kode_Kelas_20.0', 'Kode_Kelas_21.0', 'Kode_Kelas_22.0', 'Kode_Kelas_23.0', 'Kode_Kelas_24.0', 'Kode_Kelas_25.0', 'Kode_Kelas_26.0', 'Kode_Kelas_27.0', 'Kode_Kelas_28.0', 'Kode_Kelas_29.0', 'Kode_Kelas_30.0', 'Kode_Kelas_31.0', 'Kode_Kelas_32.0', 'Kode_Kelas_33.0', 'Kode_Kelas_34.0', 'Kode_Kelas_35.0', 'Kode_Kelas_36.0', 'Kode_Kelas_37.0', 'Kode_Kelas_38.0', 'Kode_Kelas_39.0', 'Kode_Kelas_40.0', 'Kode_Kelas_41.0', 'Kode_Kelas_42.0', 'Kode_Kelas_43.0', 'Kode_Kelas_44.0', 'Kode_Kelas_45.0', 'Kode_Kelas_99.0', 'Brand', 'Logo File', 'Status_Encoded', 'Nama Pemilik', 'Nomor Permohonan', 'Deskripsi Kelas', 'Nama Pemilik_normalized', 'Brand_Owner_Group']\n\nJumlah baris dengan brand generik ('LOGO' dll.) untuk split: 5493\nJumlah baris dengan brand unik lainnya untuk split: 330742\n\nMelakukan Grouped Train-Validation-Test Split...\n\nFinal Shape df_train: (215965, 56)\nFinal Shape df_val: (54043, 56)\nFinal Shape df_test: (67326, 56)\n\nMenyimpan split dataset ke: /kaggle/working/final_dataset_splits/\nIndividual split datasets berhasil disimpan dalam format CSV.\nFull combined dataset juga disimpan sebagai 'full_dataset_with_splits.csv'.\n\nPipeline pra-pemrosesan dan split selesai. Dataset siap digunakan.\nFinal dataset with splits shape: (215965, 56)\nFinal dataset with splits shape: (54043, 56)\nFinal dataset with splits shape: (67326, 56)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"y_train_full = X_train_full['Status_Encoded'] \ny_val_full = X_val_full['Status_Encoded']\ny_test_full = X_test_full['Status_Encoded']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T22:50:45.104220Z","iopub.execute_input":"2025-07-08T22:50:45.104953Z","iopub.status.idle":"2025-07-08T22:50:45.111125Z","shell.execute_reply.started":"2025-07-08T22:50:45.104929Z","shell.execute_reply":"2025-07-08T22:50:45.110350Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import re\nimport numpy as np \n\ndef clean_brand_name(brand_text):\n    \"\"\"\n    Membersihkan nama brand berdasarkan logika spesifik:\n    1. Jika persis 'logo' (case-insensitive), ganti dengan string kosong \"\".\n    2. Jika mengandung 'logo' (case-insensitive) DAN ada tanda baca ('+' atau '&'),\n       hapus 'logo' beserta tanda baca dan spasi di sekitarnya.\n    3. Jika mengandung 'logo' (case-insensitive) NAMUN TIDAK ada tanda baca ('+' atau '&'),\n       hapus hanya 'logo' beserta spasi di sekitarnya.\n    4. Selain itu, lakukan normalisasi dasar (huruf kecil, hapus spasi berlebih).\n\n    Args:\n        brand_text (str): Nama brand yang akan dibersihkan.\n\n    Returns:\n        str: Nama brand yang sudah dibersihkan.\n    \"\"\"\n    if not isinstance(brand_text, str):\n        return '' \n\n    original_text_lower = brand_text.lower().strip()\n\n    if original_text_lower == 'logo':\n        return ''\n\n    has_logo_substring = 'logo' in original_text_lower\n    \n    has_punctuation = bool(re.search(r'[+&]', original_text_lower))\n\n    if has_logo_substring and has_punctuation:\n        cleaned_text = re.sub(r'\\s*[+&]*\\s*logo\\s*[+&]*\\s*', '', original_text_lower)\n        cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip() \n        return cleaned_text\n    \n   \n    if has_logo_substring and not has_punctuation:\n        cleaned_text = re.sub(r'\\s*logo\\s*', '', original_text_lower)\n        cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip() \n        return cleaned_text\n    \n    return original_text_lower","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T13:07:52.543723Z","iopub.execute_input":"2025-07-09T13:07:52.544010Z","iopub.status.idle":"2025-07-09T13:07:52.550360Z","shell.execute_reply.started":"2025-07-09T13:07:52.543989Z","shell.execute_reply":"2025-07-09T13:07:52.549653Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"print(\"\\nMenerapkan clean_brand_name ke kolom 'Brand'...\")\n\nprint(\"\\n--- X_train_full ---\")\nX_train_full['Brand'] = X_train_full['Brand'].apply(clean_brand_name)\nprint(X_train_full[['Brand']].head())\nprint(f\"Jumlah brand kosong di X_train_full: {len(X_train_full[X_train_full['Brand'] == ''])}\")\n\nprint(\"\\n--- X_val_full ---\")\nX_val_full['Brand'] = X_val_full['Brand'].apply(clean_brand_name)\nprint(X_val_full[['Brand']].head())\nprint(f\"Jumlah brand kosong di X_val_full: {len(X_val_full[X_val_full['Brand'] == ''])}\")\n\n\nprint(\"\\n--- X_test_full ---\")\nX_test_full['Brand'] = X_test_full['Brand'].apply(clean_brand_name)\nprint(X_test_full[['Brand']].head())\nprint(f\"Jumlah brand kosong di X_test_full: {len(X_test_full[X_test_full['Brand'] == ''])}\")\n\nprint(\"\\nPembersihan nama brand selesai untuk semua dataset split.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T13:07:55.662859Z","iopub.execute_input":"2025-07-09T13:07:55.663534Z","iopub.status.idle":"2025-07-09T13:07:56.083214Z","shell.execute_reply.started":"2025-07-09T13:07:55.663502Z","shell.execute_reply":"2025-07-09T13:07:56.082314Z"}},"outputs":[{"name":"stdout","text":"\nMenerapkan clean_brand_name ke kolom 'Brand'...\n\n--- X_train_full ---\n                 Brand\n0  daramanis + lukisan\n1               nasaky\n2         99 sembilan2\n3           badarawuhi\n4            travelink\nJumlah brand kosong di X_train_full: 4395\n\n--- X_val_full ---\n             Brand\n0         shinmade\n1          andicol\n2  bumi lubricants\n3           dvanco\n4          hs glow\nJumlah brand kosong di X_val_full: 1099\n\n--- X_test_full ---\n      Brand\n0     d'nox\n1     ika's\n2  itronics\n3    eldove\n4     canon\nJumlah brand kosong di X_test_full: 1102\n\nPembersihan nama brand selesai untuk semua dataset split.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"X_train_full.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T01:02:24.319884Z","iopub.execute_input":"2025-07-09T01:02:24.320564Z","iopub.status.idle":"2025-07-09T01:02:24.337152Z","shell.execute_reply.started":"2025-07-09T01:02:24.320540Z","shell.execute_reply":"2025-07-09T01:02:24.336430Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"   Tahun Permohonan  Kode_Kelas_1.0  Kode_Kelas_2.0  Kode_Kelas_3.0  \\\n0              2020           False           False           False   \n1              2015           False           False           False   \n2              2004           False           False           False   \n3              2022           False           False           False   \n4              2017           False           False           False   \n\n   Kode_Kelas_4.0  Kode_Kelas_5.0  Kode_Kelas_6.0  Kode_Kelas_7.0  \\\n0           False           False           False           False   \n1           False           False           False           False   \n2           False           False           False           False   \n3           False           False           False           False   \n4           False           False           False           False   \n\n   Kode_Kelas_8.0  Kode_Kelas_9.0  ...  brand_emb_1023  \\\n0           False           False  ...        0.025274   \n1           False           False  ...        0.020340   \n2           False           False  ...        0.015658   \n3           False           False  ...        0.027659   \n4           False           False  ...        0.009313   \n\n   max_sim_to_rejected_brand_train  year_of_most_sim_rejected_brand_train  \\\n0                         0.987026                                   2020   \n1                         0.959297                                   2018   \n2                         0.964161                                   2021   \n3                         1.000000                                   2022   \n4                         0.964819                                   2019   \n\n   max_sim_to_registered_brand_train  year_of_most_sim_registered_brand_train  \\\n0                           0.988250                                     2016   \n1                           0.960990                                     2011   \n2                           0.961710                                     2003   \n3                           1.000000                                     2022   \n4                           0.960867                                     2020   \n\n   year_gap_to_most_sim_rejected  year_gap_to_most_sim_registered  \\\n0                              0                                4   \n1                             -3                                4   \n2                            -17                                1   \n3                              0                                0   \n4                             -2                               -3   \n\n   num_rejected_in_class_train  num_registered_in_class_train  \\\n0                       7976.0                        15063.0   \n1                        862.0                         3193.0   \n2                       7976.0                        15063.0   \n3                       1456.0                         5379.0   \n4                        862.0                         3193.0   \n\n   rejection_rate_in_class_train  \n0                       0.346196  \n1                       0.212577  \n2                       0.346196  \n3                       0.213021  \n4                       0.212577  \n\n[5 rows x 1086 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tahun Permohonan</th>\n      <th>Kode_Kelas_1.0</th>\n      <th>Kode_Kelas_2.0</th>\n      <th>Kode_Kelas_3.0</th>\n      <th>Kode_Kelas_4.0</th>\n      <th>Kode_Kelas_5.0</th>\n      <th>Kode_Kelas_6.0</th>\n      <th>Kode_Kelas_7.0</th>\n      <th>Kode_Kelas_8.0</th>\n      <th>Kode_Kelas_9.0</th>\n      <th>...</th>\n      <th>brand_emb_1023</th>\n      <th>max_sim_to_rejected_brand_train</th>\n      <th>year_of_most_sim_rejected_brand_train</th>\n      <th>max_sim_to_registered_brand_train</th>\n      <th>year_of_most_sim_registered_brand_train</th>\n      <th>year_gap_to_most_sim_rejected</th>\n      <th>year_gap_to_most_sim_registered</th>\n      <th>num_rejected_in_class_train</th>\n      <th>num_registered_in_class_train</th>\n      <th>rejection_rate_in_class_train</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>0.025274</td>\n      <td>0.987026</td>\n      <td>2020</td>\n      <td>0.988250</td>\n      <td>2016</td>\n      <td>0</td>\n      <td>4</td>\n      <td>7976.0</td>\n      <td>15063.0</td>\n      <td>0.346196</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2015</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>0.020340</td>\n      <td>0.959297</td>\n      <td>2018</td>\n      <td>0.960990</td>\n      <td>2011</td>\n      <td>-3</td>\n      <td>4</td>\n      <td>862.0</td>\n      <td>3193.0</td>\n      <td>0.212577</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2004</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>0.015658</td>\n      <td>0.964161</td>\n      <td>2021</td>\n      <td>0.961710</td>\n      <td>2003</td>\n      <td>-17</td>\n      <td>1</td>\n      <td>7976.0</td>\n      <td>15063.0</td>\n      <td>0.346196</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2022</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>0.027659</td>\n      <td>1.000000</td>\n      <td>2022</td>\n      <td>1.000000</td>\n      <td>2022</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1456.0</td>\n      <td>5379.0</td>\n      <td>0.213021</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2017</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>0.009313</td>\n      <td>0.964819</td>\n      <td>2019</td>\n      <td>0.960867</td>\n      <td>2020</td>\n      <td>-2</td>\n      <td>-3</td>\n      <td>862.0</td>\n      <td>3193.0</td>\n      <td>0.212577</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 1086 columns</p>\n</div>"},"metadata":{}}],"execution_count":30},{"cell_type":"markdown","source":"# Set Device ke CUDA untuk jika ada proses embeddings","metadata":{}},{"cell_type":"code","source":"import mlflow\nimport torch\n\nmlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T01:14:04.267230Z","iopub.execute_input":"2025-07-10T01:14:04.267531Z","iopub.status.idle":"2025-07-10T01:14:11.411195Z","shell.execute_reply.started":"2025-07-10T01:14:04.267501Z","shell.execute_reply":"2025-07-10T01:14:11.410380Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"X_train_full.to_parquet('Training_image.parquet', index = False)\nX_val_full.to_parquet('Validation_image.parquet', index = False)\nX_test_full.to_parquet('Test_image.parquet', index = False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T03:31:38.776737Z","iopub.execute_input":"2025-07-10T03:31:38.777024Z","iopub.status.idle":"2025-07-10T03:31:45.892676Z","shell.execute_reply.started":"2025-07-10T03:31:38.777004Z","shell.execute_reply":"2025-07-10T03:31:45.891780Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"X_train_full.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T14:23:06.788693Z","iopub.execute_input":"2025-07-09T14:23:06.789006Z","iopub.status.idle":"2025-07-09T14:23:07.028547Z","shell.execute_reply.started":"2025-07-09T14:23:06.788987Z","shell.execute_reply":"2025-07-09T14:23:07.027663Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"   Tahun Permohonan  Kode_Kelas_1.0  Kode_Kelas_2.0  Kode_Kelas_3.0  \\\n0              2020           False           False           False   \n1              2015           False           False           False   \n2              2004           False           False           False   \n3              2022           False           False           False   \n4              2017           False           False           False   \n\n   Kode_Kelas_4.0  Kode_Kelas_5.0  Kode_Kelas_6.0  Kode_Kelas_7.0  \\\n0           False           False           False           False   \n1           False           False           False           False   \n2           False           False           False           False   \n3           False           False           False           False   \n4           False           False           False           False   \n\n   Kode_Kelas_8.0  Kode_Kelas_9.0  ...  brand_sparse_emb_767  \\\n0           False           False  ...             -0.078687   \n1           False           False  ...             -0.610178   \n2           False           False  ...             -0.289164   \n3           False           False  ...             -0.098687   \n4           False           False  ...             -0.663434   \n\n   max_sim_to_rejected_brand_train  year_of_most_sim_rejected_brand_train  \\\n0                         0.914262                                   2017   \n1                         0.807589                                   2019   \n2                         0.793662                                   2014   \n3                         1.000000                                   2022   \n4                         0.823312                                   2022   \n\n   max_sim_to_registered_brand_train  year_of_most_sim_registered_brand_train  \\\n0                           0.922288                                     2003   \n1                           0.826382                                     2024   \n2                           0.827081                                     2009   \n3                           1.000000                                     2022   \n4                           0.830813                                     2018   \n\n   year_gap_to_most_sim_rejected  year_gap_to_most_sim_registered  \\\n0                              3                               17   \n1                             -4                               -9   \n2                            -10                               -5   \n3                              0                                0   \n4                             -5                               -1   \n\n   num_rejected_in_class_train  num_registered_in_class_train  \\\n0                       7976.0                        15063.0   \n1                        862.0                         3193.0   \n2                       7976.0                        15063.0   \n3                       1456.0                         5379.0   \n4                        862.0                         3193.0   \n\n   rejection_rate_in_class_train  \n0                       0.346196  \n1                       0.212577  \n2                       0.346196  \n3                       0.213021  \n4                       0.212577  \n\n[5 rows x 832 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tahun Permohonan</th>\n      <th>Kode_Kelas_1.0</th>\n      <th>Kode_Kelas_2.0</th>\n      <th>Kode_Kelas_3.0</th>\n      <th>Kode_Kelas_4.0</th>\n      <th>Kode_Kelas_5.0</th>\n      <th>Kode_Kelas_6.0</th>\n      <th>Kode_Kelas_7.0</th>\n      <th>Kode_Kelas_8.0</th>\n      <th>Kode_Kelas_9.0</th>\n      <th>...</th>\n      <th>brand_sparse_emb_767</th>\n      <th>max_sim_to_rejected_brand_train</th>\n      <th>year_of_most_sim_rejected_brand_train</th>\n      <th>max_sim_to_registered_brand_train</th>\n      <th>year_of_most_sim_registered_brand_train</th>\n      <th>year_gap_to_most_sim_rejected</th>\n      <th>year_gap_to_most_sim_registered</th>\n      <th>num_rejected_in_class_train</th>\n      <th>num_registered_in_class_train</th>\n      <th>rejection_rate_in_class_train</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>-0.078687</td>\n      <td>0.914262</td>\n      <td>2017</td>\n      <td>0.922288</td>\n      <td>2003</td>\n      <td>3</td>\n      <td>17</td>\n      <td>7976.0</td>\n      <td>15063.0</td>\n      <td>0.346196</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2015</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>-0.610178</td>\n      <td>0.807589</td>\n      <td>2019</td>\n      <td>0.826382</td>\n      <td>2024</td>\n      <td>-4</td>\n      <td>-9</td>\n      <td>862.0</td>\n      <td>3193.0</td>\n      <td>0.212577</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2004</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>-0.289164</td>\n      <td>0.793662</td>\n      <td>2014</td>\n      <td>0.827081</td>\n      <td>2009</td>\n      <td>-10</td>\n      <td>-5</td>\n      <td>7976.0</td>\n      <td>15063.0</td>\n      <td>0.346196</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2022</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>-0.098687</td>\n      <td>1.000000</td>\n      <td>2022</td>\n      <td>1.000000</td>\n      <td>2022</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1456.0</td>\n      <td>5379.0</td>\n      <td>0.213021</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2017</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>-0.663434</td>\n      <td>0.823312</td>\n      <td>2022</td>\n      <td>0.830813</td>\n      <td>2018</td>\n      <td>-5</td>\n      <td>-1</td>\n      <td>862.0</td>\n      <td>3193.0</td>\n      <td>0.212577</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 832 columns</p>\n</div>"},"metadata":{}}],"execution_count":16},{"cell_type":"markdown","source":"# Proses DENSE Embedding pada Kolom \"Brand\" untuk setiap dataset","metadata":{}},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nimport pandas as pd\nimport numpy as np\nfrom tqdm.auto import tqdm \n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nMODEL_NAME = 'intfloat/multilingual-e5-large-instruct'\nembedding_model = SentenceTransformer(MODEL_NAME, device=device)\n\nINTERNAL_BATCH_SIZE = 64 \nprint(\"Creating embeddings for 'Brand' train...\")\nbrand_embeddings_train = embedding_model.encode(\n    X_train_full['Brand'].tolist(),\n    show_progress_bar=True,\n    convert_to_numpy=True,\n    batch_size=INTERNAL_BATCH_SIZE \n)\nprint(\"Creating embeddings for 'Brand' val...\")\nbrand_embeddings_val = embedding_model.encode(\n    X_val_full['Brand'].tolist(),\n    show_progress_bar=True,\n    convert_to_numpy=True,\n    batch_size=INTERNAL_BATCH_SIZE \n)\nprint(\"Creating embeddings for 'Brand' test...\")\nbrand_embeddings_test = embedding_model.encode(\n    X_test_full['Brand'].tolist(),\n    show_progress_bar=True,\n    convert_to_numpy=True,\n    batch_size=INTERNAL_BATCH_SIZE ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T22:54:19.861576Z","iopub.execute_input":"2025-07-08T22:54:19.862246Z","iopub.status.idle":"2025-07-08T23:05:19.727341Z","shell.execute_reply.started":"2025-07-08T22:54:19.862217Z","shell.execute_reply":"2025-07-08T23:05:19.726478Z"}},"outputs":[{"name":"stderr","text":"2025-07-08 22:54:28.541024: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1752015268.723509      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1752015268.776336      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40a9445ce98d462e9f2d91dc1371d091"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/128 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb25f5a31145408f9d3b2675af45db71"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e899adc00694d73a6f46c73a02ffd12"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_xlm-roberta_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aab4bae2440f48539af8a3dc5b1770ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/690 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e56bc268866c4c1d8e38842be815cfb7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3be6f3e463394986b7abce0f1df0e606"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3bad024e15da4cd986a3bebb1daff7d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fbc0d66b8164c0cbe7ca64323d4abc2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94ad43404ab94028b4bcdf8e062a0703"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc62e5fe750749a482757d219e4ae50a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/271 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46b4ab5f39f24250b9ef7465e9053251"}},"metadata":{}},{"name":"stdout","text":"Creating embeddings for 'Brand' train...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/3375 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"572b38dc89d743b8a13af4c2d8b7fc46"}},"metadata":{}},{"name":"stdout","text":"Creating embeddings for 'Brand' val...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/845 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dedbe924fb8346019be77da1c5e67315"}},"metadata":{}},{"name":"stdout","text":"Creating embeddings for 'Brand' test...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1052 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc4dfe7c176a4aedb58f5bac3469d8d5"}},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"# Menggabungkan embeddings ke Dataframe awal","metadata":{}},{"cell_type":"code","source":"brand_embeddings_df_train = pd.DataFrame(brand_embeddings_train, index=X_train_full.index)\nbrand_embeddings_df_train.columns = [f'brand_emb_{i}' for i in range(brand_embeddings_df_train.shape[1])]\n\nbrand_embeddings_df_val = pd.DataFrame(brand_embeddings_val, index=X_val_full.index)\nbrand_embeddings_df_val.columns = [f'brand_emb_{i}' for i in range(brand_embeddings_df_val.shape[1])]\n\nbrand_embeddings_df_test = pd.DataFrame(brand_embeddings_test, index=X_test_full.index)\nbrand_embeddings_df_test.columns = [f'brand_emb_{i}' for i in range(brand_embeddings_df_test.shape[1])]\n\nnumerical_and_ohe_cols = [col for col in X_train_full.columns if col not in ['Brand', 'Deskripsi Kelas', 'Status_Encoded']]\nX_train_full = pd.concat([X_train_full[numerical_and_ohe_cols], brand_embeddings_df_train], axis=1)\nnumerical_and_ohe_cols = [col for col in X_val_full.columns if col not in ['Brand', 'Deskripsi Kelas', 'Status_Encoded']]\nX_val_full = pd.concat([X_val_full[numerical_and_ohe_cols], brand_embeddings_df_val], axis=1)\nnumerical_and_ohe_cols = [col for col in X_test_full.columns if col not in ['Brand', 'Deskripsi Kelas', 'Status_Encoded']]\nX_test_full = pd.concat([X_test_full[numerical_and_ohe_cols], brand_embeddings_df_test], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T23:43:33.797763Z","iopub.execute_input":"2025-07-08T23:43:33.798342Z","iopub.status.idle":"2025-07-08T23:43:34.570793Z","shell.execute_reply.started":"2025-07-08T23:43:33.798317Z","shell.execute_reply":"2025-07-08T23:43:34.570156Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"# Sparse Embedding Encoding ","metadata":{}},{"cell_type":"code","source":"import torch\nfrom sentence_transformers import SentenceTransformer\nimport pandas as pd\nimport numpy as np\nfrom tqdm.auto import tqdm\nimport gc\nfrom scipy.sparse import csr_matrix \nimport os \n\nprint(f\"Shape X_train_full (loaded): {X_train_full.shape}\")\nprint(f\"Shape X_val_full (loaded): {X_val_full.shape}\")\nprint(f\"Shape X_test_full (loaded): {X_test_full.shape}\")\n\nSPARSE_MODEL_NAME = 'opensearch-project/opensearch-neural-sparse-encoding-multilingual-v1'\ndevice_sparse = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nprint(f\"\\nMemuat model Sparse Embedding: {SPARSE_MODEL_NAME}...\")\nsparse_embedding_model = SentenceTransformer(SPARSE_MODEL_NAME, device=device_sparse)\nprint(\"Model Sparse Embedding berhasil dimuat.\")\n\nSPARSE_EMBEDDING_OUTPUT_DIM = 25000 \n\nINTERNAL_BATCH_SIZE_SPARSE = 512 \n\ndef convert_dense_array_to_sparse_df(dense_embeddings_array, output_dim, dataframe_index):\n    \"\"\"\n    Mengkonversi dense NumPy array (output dari encode) menjadi scipy.sparse.csr_matrix\n    dan kemudian ke Pandas DataFrame dengan SparseDtype.\n    \"\"\"\n    if dense_embeddings_array.shape[1] != output_dim:\n        print(f\"Peringatan: Dimensi output {dense_embeddings_array.shape[1]} tidak sesuai dengan {output_dim}. Lanjutkan, tapi periksa model.\")\n       \n    csr_matrix_result = csr_matrix(dense_embeddings_array, dtype=np.float32)\n    \n    sparse_df = pd.DataFrame.sparse.from_spmatrix(csr_matrix_result, index=dataframe_index)\n    return sparse_df\n\nprint(\"\\nCreating Sparse Embeddings for 'Brand' train (as NumPy Array)...\")\nbrand_sparse_embeddings_train_raw = sparse_embedding_model.encode(\n    X_train_full['Brand'].tolist(),\n    show_progress_bar=True,\n    convert_to_numpy=True, #\n    batch_size=INTERNAL_BATCH_SIZE_SPARSE\n)\n\nprint(\"Creating Sparse Embeddings for 'Brand' val (as NumPy Array)...\")\nbrand_sparse_embeddings_val_raw = sparse_embedding_model.encode(\n    X_val_full['Brand'].tolist(),\n    show_progress_bar=True,\n    convert_to_numpy=True, \n    batch_size=INTERNAL_BATCH_SIZE_SPARSE\n)\n\nprint(\"Creating Sparse Embeddings for 'Brand' test (as NumPy Array)...\")\nbrand_sparse_embeddings_test_raw = sparse_embedding_model.encode(\n    X_test_full['Brand'].tolist(),\n    show_progress_bar=True,\n    convert_to_numpy=True, \n    batch_size=INTERNAL_BATCH_SIZE_SPARSE\n)\n\ndel sparse_embedding_model\nif device_sparse.type == 'cuda':\n    torch.cuda.empty_cache()\ngc.collect()\n\n\nprint(\"\\nMengkonversi Brand Sparse Embeddings (NumPy Array) ke Sparse DataFrame...\")\nbrand_embeddings_df_train = convert_dense_array_to_sparse_df(brand_sparse_embeddings_train_raw, SPARSE_EMBEDDING_OUTPUT_DIM, X_train_full.index)\nbrand_embeddings_df_val = convert_dense_array_to_sparse_df(brand_sparse_embeddings_val_raw, SPARSE_EMBEDDING_OUTPUT_DIM, X_val_full.index)\nbrand_embeddings_df_test = convert_dense_array_to_sparse_df(brand_sparse_embeddings_test_raw, SPARSE_EMBEDDING_OUTPUT_DIM, X_test_full.index)\n\nbrand_embeddings_df_train.columns = [f'brand_sparse_emb_{i}' for i in range(brand_embeddings_df_train.shape[1])]\nbrand_embeddings_df_val.columns = [f'brand_sparse_emb_{i}' for i in range(brand_embeddings_df_val.shape[1])]\nbrand_embeddings_df_test.columns = [f'brand_sparse_emb_{i}' for i in range(brand_embeddings_df_test.shape[1])]\nprint(\"Brand Sparse Embeddings berhasil dikonversi ke Sparse DataFrame.\")\n\ndel brand_sparse_embeddings_train_raw, brand_sparse_embeddings_val_raw, brand_sparse_embeddings_test_raw\ngc.collect()\n\nX_train_full = pd.concat([X_train_full, brand_embeddings_df_train], axis=1)\nX_val_full = pd.concat([X_val_full, brand_embeddings_df_val], axis=1)\nX_test_full = pd.concat([X_test_full, brand_embeddings_df_test], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T13:08:36.804627Z","iopub.execute_input":"2025-07-09T13:08:36.804952Z","iopub.status.idle":"2025-07-09T13:12:46.944252Z","shell.execute_reply.started":"2025-07-09T13:08:36.804932Z","shell.execute_reply":"2025-07-09T13:12:46.943402Z"}},"outputs":[{"name":"stderr","text":"2025-07-09 13:08:48.555082: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1752066528.925020      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1752066529.028783      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Shape X_train_full (loaded): (215965, 55)\nShape X_val_full (loaded): (54043, 55)\nShape X_test_full (loaded): (67326, 55)\n\nMemuat model Sparse Embedding: opensearch-project/opensearch-neural-sparse-encoding-multilingual-v1...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/108 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7bbf6700ab04015ace1310227550392"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/274 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f22913d8cb5461e91d0d39192e27ddd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/872 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5e8bbcbbd6f4ecabf56763d382c699e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/670M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"424fc827e2a846fe91b0fb231e0e60dc"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertModel were not initialized from the model checkpoint at opensearch-project/opensearch-neural-sparse-encoding-multilingual-v1 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ceef8e437479412ab14bdb51dfbcf2ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35a6faeaaf8a4c97a5ac4e3c5d187b16"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"168d4ac7a407452b9a6fea1c5c780e92"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2778455e69d940488b7633040325054c"}},"metadata":{}},{"name":"stdout","text":"Model Sparse Embedding berhasil dimuat.\n\nCreating Sparse Embeddings for 'Brand' train (as NumPy Array)...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/422 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6bc2306ec39e430ba9c38a9843efad83"}},"metadata":{}},{"name":"stdout","text":"Creating Sparse Embeddings for 'Brand' val (as NumPy Array)...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/106 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b2bdbc1012944c1bebf1ce750e20d05"}},"metadata":{}},{"name":"stdout","text":"Creating Sparse Embeddings for 'Brand' test (as NumPy Array)...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/132 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17ca3627905f4a7f9841e8f2431309a0"}},"metadata":{}},{"name":"stdout","text":"\nMengkonversi Brand Sparse Embeddings (NumPy Array) ke Sparse DataFrame...\nPeringatan: Dimensi output 768 tidak sesuai dengan 25000. Lanjutkan, tapi periksa model.\nPeringatan: Dimensi output 768 tidak sesuai dengan 25000. Lanjutkan, tapi periksa model.\nPeringatan: Dimensi output 768 tidak sesuai dengan 25000. Lanjutkan, tapi periksa model.\nBrand Sparse Embeddings berhasil dikonversi ke Sparse DataFrame.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"X_train_full.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T13:13:18.594081Z","iopub.execute_input":"2025-07-09T13:13:18.594627Z","iopub.status.idle":"2025-07-09T13:13:18.825613Z","shell.execute_reply.started":"2025-07-09T13:13:18.594594Z","shell.execute_reply":"2025-07-09T13:13:18.824775Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"   Tahun Permohonan  Kode_Kelas_1.0  Kode_Kelas_2.0  Kode_Kelas_3.0  \\\n0              2020           False           False           False   \n1              2015           False           False           False   \n2              2004           False           False           False   \n3              2022           False           False           False   \n4              2017           False           False           False   \n\n   Kode_Kelas_4.0  Kode_Kelas_5.0  Kode_Kelas_6.0  Kode_Kelas_7.0  \\\n0           False           False           False           False   \n1           False           False           False           False   \n2           False           False           False           False   \n3           False           False           False           False   \n4           False           False           False           False   \n\n   Kode_Kelas_8.0  Kode_Kelas_9.0  ...  brand_sparse_emb_758  \\\n0           False           False  ...             -0.012787   \n1           False           False  ...              0.040905   \n2           False           False  ...             -0.186787   \n3           False           False  ...             -0.135766   \n4           False           False  ...              0.008693   \n\n   brand_sparse_emb_759  brand_sparse_emb_760  brand_sparse_emb_761  \\\n0              0.035128              -0.31209              0.029701   \n1             -0.188857             -0.516438              0.048114   \n2              0.121386             -0.456464             -0.087706   \n3              0.039379             -0.370459              0.073069   \n4              0.045462             -0.380452               0.19267   \n\n   brand_sparse_emb_762  brand_sparse_emb_763  brand_sparse_emb_764  \\\n0              0.018304              0.394299             -0.261753   \n1             -0.378785              0.026625             -0.300425   \n2             -0.389609              0.216327             -0.472879   \n3             -0.318064              0.212209              -0.54372   \n4             -0.260486             -0.292189             -0.142892   \n\n   brand_sparse_emb_765  brand_sparse_emb_766  brand_sparse_emb_767  \n0             -0.017945              0.102289             -0.078687  \n1              0.065108             -0.189775             -0.610178  \n2              0.414404              0.002909             -0.289164  \n3              0.063037              0.136826             -0.098687  \n4              0.162027             -0.098577             -0.663434  \n\n[5 rows x 823 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tahun Permohonan</th>\n      <th>Kode_Kelas_1.0</th>\n      <th>Kode_Kelas_2.0</th>\n      <th>Kode_Kelas_3.0</th>\n      <th>Kode_Kelas_4.0</th>\n      <th>Kode_Kelas_5.0</th>\n      <th>Kode_Kelas_6.0</th>\n      <th>Kode_Kelas_7.0</th>\n      <th>Kode_Kelas_8.0</th>\n      <th>Kode_Kelas_9.0</th>\n      <th>...</th>\n      <th>brand_sparse_emb_758</th>\n      <th>brand_sparse_emb_759</th>\n      <th>brand_sparse_emb_760</th>\n      <th>brand_sparse_emb_761</th>\n      <th>brand_sparse_emb_762</th>\n      <th>brand_sparse_emb_763</th>\n      <th>brand_sparse_emb_764</th>\n      <th>brand_sparse_emb_765</th>\n      <th>brand_sparse_emb_766</th>\n      <th>brand_sparse_emb_767</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>-0.012787</td>\n      <td>0.035128</td>\n      <td>-0.31209</td>\n      <td>0.029701</td>\n      <td>0.018304</td>\n      <td>0.394299</td>\n      <td>-0.261753</td>\n      <td>-0.017945</td>\n      <td>0.102289</td>\n      <td>-0.078687</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2015</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>0.040905</td>\n      <td>-0.188857</td>\n      <td>-0.516438</td>\n      <td>0.048114</td>\n      <td>-0.378785</td>\n      <td>0.026625</td>\n      <td>-0.300425</td>\n      <td>0.065108</td>\n      <td>-0.189775</td>\n      <td>-0.610178</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2004</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>-0.186787</td>\n      <td>0.121386</td>\n      <td>-0.456464</td>\n      <td>-0.087706</td>\n      <td>-0.389609</td>\n      <td>0.216327</td>\n      <td>-0.472879</td>\n      <td>0.414404</td>\n      <td>0.002909</td>\n      <td>-0.289164</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2022</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>-0.135766</td>\n      <td>0.039379</td>\n      <td>-0.370459</td>\n      <td>0.073069</td>\n      <td>-0.318064</td>\n      <td>0.212209</td>\n      <td>-0.54372</td>\n      <td>0.063037</td>\n      <td>0.136826</td>\n      <td>-0.098687</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2017</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>0.008693</td>\n      <td>0.045462</td>\n      <td>-0.380452</td>\n      <td>0.19267</td>\n      <td>-0.260486</td>\n      <td>-0.292189</td>\n      <td>-0.142892</td>\n      <td>0.162027</td>\n      <td>-0.098577</td>\n      <td>-0.663434</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 823 columns</p>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"# Fungsi Fitur-Fitur berbasis Cosine Similarity","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics.pairwise import cosine_similarity\nimport pandas as pd\nimport numpy as np\nfrom tqdm.auto import tqdm \nimport gc \nfrom sklearn.model_selection import StratifiedKFold \n\n\nprint(f\"\\nShape X_train (loaded): {X_train_full.shape}\")\nprint(f\"Shape X_val (loaded): {X_val_full.shape}\")\nprint(f\"Shape X_test (loaded): {X_test_full.shape}\")\nprint(f\"Shape y_train (loaded): {y_train_full.shape}\")\nprint(f\"Shape y_val (loaded): {y_val_full.shape}\")\nprint(f\"Shape y_test (loaded): {y_test_full.shape}\")\n\n\nbrand_emb_cols_prefix = 'brand_sparse_emb_' \nbrand_emb_cols = [col for col in X_train_full.columns if col.startswith(brand_emb_cols_prefix)]\n\nif not brand_emb_cols:\n    raise ValueError(f\"Kolom embeddings Brand ({brand_emb_cols_prefix}X) tidak ditemukan di X_train_full. Tidak dapat menghitung kemiripan.\")\nif 'Tahun Permohonan' not in X_train_full.columns:\n    raise ValueError(\"Kolom 'Tahun Permohonan' tidak ditemukan di X_train_full.\")\nprint(f\"\\nDitemukan {len(brand_emb_cols)} kolom Brand Embeddings ({brand_emb_cols_prefix}).\")\n\nrejected_train_indices_global = y_train_full[y_train_full == 0].index\nregistered_train_indices_global = y_train_full[y_train_full == 1].index\n\nrejected_brand_embeddings_train_global = X_train_full.loc[rejected_train_indices_global, brand_emb_cols].values\nrejected_brand_years_train_global = X_train_full.loc[rejected_train_indices_global, 'Tahun Permohonan'].values\n\nregistered_brand_embeddings_train_global = X_train_full.loc[registered_train_indices_global, brand_emb_cols].values\nregistered_brand_years_train_global = X_train_full.loc[registered_train_indices_global, 'Tahun Permohonan'].values\n\n\nprint(f\"Jumlah sampel 'Ditolak' di set pelatihan global untuk referensi: {rejected_brand_embeddings_train_global.shape[0]}\")\nprint(f\"Jumlah sampel 'Didaftar' di set pelatihan global untuk referensi: {registered_brand_embeddings_train_global.shape[0]}\")\n\n\ndef calculate_enriched_similarity_feature_batched(target_df, reference_embeddings_np, reference_years_np, brand_emb_cols, batch_size=2000):\n    \"\"\"\n    Menghitung fitur 'max_sim' dan 'year_of_max_sim' untuk DataFrame target dalam batch.\n    \"\"\"\n    if reference_embeddings_np.shape[0] == 0:\n        return np.zeros(target_df.shape[0], dtype=np.float32), np.full(target_df.shape[0], -1, dtype=np.int32) # -1 untuk tahun tidak ditemukan\n\n    all_max_similarities = []\n    all_years_of_max_similarities = []\n    \n    target_brand_embeddings_np_full = target_df[brand_emb_cols].values\n    target_years_np_full = target_df['Tahun Permohonan'].values\n\n    for i in tqdm(range(0, target_brand_embeddings_np_full.shape[0], batch_size), desc=\"Calculating Enriched Similarity\"):\n        batch_target_embeddings = target_brand_embeddings_np_full[i : i + batch_size]\n        batch_target_years = target_years_np_full[i : i + batch_size]\n\n        similarities_batch = cosine_similarity(batch_target_embeddings, reference_embeddings_np)\n        \n        max_similarities_batch = np.max(similarities_batch, axis=1)\n        max_similarity_indices_batch = np.argmax(similarities_batch, axis=1)\n\n        years_of_max_similarities_batch = reference_years_np[max_similarity_indices_batch]\n\n        all_max_similarities.append(max_similarities_batch)\n        all_years_of_max_similarities.append(years_of_max_similarities_batch)\n        \n        del batch_target_embeddings, batch_target_years, similarities_batch, max_similarities_batch, max_similarity_indices_batch, years_of_max_similarities_batch\n        gc.collect()\n\n    return np.concatenate(all_max_similarities).astype(np.float32), np.concatenate(all_years_of_max_similarities).astype(np.int32)\n\n\ndef calculate_oof_similarity_features(X_train_df, y_train_series, brand_emb_cols, n_splits=5, random_state=42, batch_size=2000):\n    \"\"\"\n    Menghitung fitur kemiripan (IKS dan Registered) untuk X_train_df menggunakan OOF.\n    \"\"\"\n    print(f\"\\nMenghitung OOF similarity features untuk X_train_df dengan {n_splits}-fold CV...\")\n\n    oof_max_sim_rej = np.zeros(len(X_train_df), dtype=np.float32)\n    oof_year_sim_rej = np.zeros(len(X_train_df), dtype=np.int32)\n    oof_max_sim_reg = np.zeros(len(X_train_df), dtype=np.float32)\n    oof_year_sim_reg = np.zeros(len(X_train_df), dtype=np.int32)\n\n    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n\n    for fold, (train_idx, val_idx) in tqdm(enumerate(skf.split(X_train_df, y_train_series)), total=n_splits, desc=\"OOF Folds\"):\n        X_fold_train = X_train_df.iloc[train_idx]\n        y_fold_train = y_train_series.iloc[train_idx]\n        X_fold_val = X_train_df.iloc[val_idx]\n\n        rejected_fold_train_indices = y_fold_train[y_fold_train == 0].index\n        rejected_emb_fold_train = X_fold_train.loc[rejected_fold_train_indices, brand_emb_cols].values\n        rejected_years_fold_train = X_fold_train.loc[rejected_fold_train_indices, 'Tahun Permohonan'].values\n\n        registered_fold_train_indices = y_fold_train[y_fold_train == 1].index\n        registered_emb_fold_train = X_fold_train.loc[registered_fold_train_indices, brand_emb_cols].values\n        registered_years_fold_train = X_fold_train.loc[registered_fold_train_indices, 'Tahun Permohonan'].values\n\n        max_sim_val_rej, year_sim_val_rej = calculate_enriched_similarity_feature_batched(\n            X_fold_val, rejected_emb_fold_train, rejected_years_fold_train, brand_emb_cols, batch_size=batch_size\n        )\n        max_sim_val_reg, year_sim_val_reg = calculate_enriched_similarity_feature_batched(\n            X_fold_val, registered_emb_fold_train, registered_years_fold_train, brand_emb_cols, batch_size=batch_size\n        )\n        \n        oof_max_sim_rej[val_idx] = max_sim_val_rej\n        oof_year_sim_rej[val_idx] = year_sim_val_rej\n        oof_max_sim_reg[val_idx] = max_sim_val_reg\n        oof_year_sim_reg[val_idx] = year_sim_val_reg\n        \n        del X_fold_train, y_fold_train, X_fold_val, rejected_emb_fold_train, rejected_years_fold_train, \\\n            registered_emb_fold_train, registered_years_fold_train, max_sim_val_rej, year_sim_val_rej, \\\n            max_sim_val_reg, year_sim_val_reg\n        gc.collect()\n\n    return oof_max_sim_rej, oof_year_sim_rej, oof_max_sim_reg, oof_year_sim_reg\n\n\nBATCH_SIZE_COSINE_SIM = 2000 \nN_SPLITS_OOF = 5 \n\noof_max_sim_rej, oof_year_sim_rej, oof_max_sim_reg, oof_year_sim_reg = calculate_oof_similarity_features(\n    X_train_full, y_train_full, brand_emb_cols, n_splits=N_SPLITS_OOF, random_state=42, batch_size=BATCH_SIZE_COSINE_SIM\n)\nX_train_full['max_sim_to_rejected_brand_train'] = oof_max_sim_rej\nX_train_full['year_of_most_sim_rejected_brand_train'] = oof_year_sim_rej\nX_train_full['max_sim_to_registered_brand_train'] = oof_max_sim_reg\nX_train_full['year_of_most_sim_registered_brand_train'] = oof_year_sim_reg\n\n# Fitur gap tahun baru untuk Train Set\nX_train_full['year_gap_to_most_sim_rejected'] = X_train_full['Tahun Permohonan'] - X_train_full['year_of_most_sim_rejected_brand_train']\nX_train_full['year_gap_to_most_sim_registered'] = X_train_full['Tahun Permohonan'] - X_train_full['year_of_most_sim_registered_brand_train']\n\nrejected_train_indices_global = y_train_full[y_train_full == 0].index\nregistered_train_indices_global = y_train_full[y_train_full == 1].index\n\nrejected_brand_embeddings_train_global = X_train_full.loc[rejected_train_indices_global, brand_emb_cols].values\nrejected_brand_years_train_global = X_train_full.loc[rejected_train_indices_global, 'Tahun Permohonan'].values\n\nregistered_brand_embeddings_train_global = X_train_full.loc[registered_train_indices_global, brand_emb_cols].values\nregistered_brand_years_train_global = X_train_full.loc[registered_train_indices_global, 'Tahun Permohonan'].values\n\nprint(\"\\nMenghitung fitur kemiripan untuk X_val_full...\")\nmax_sim_val_rej, year_sim_val_rej = calculate_enriched_similarity_feature_batched(\n    X_val_full, rejected_brand_embeddings_train_global, rejected_brand_years_train_global, brand_emb_cols, batch_size=BATCH_SIZE_COSINE_SIM\n)\nX_val_full['max_sim_to_rejected_brand_train'] = max_sim_val_rej\nX_val_full['year_of_most_sim_rejected_brand_train'] = year_sim_val_rej\nX_val_full['year_gap_to_most_sim_rejected'] = X_val_full['Tahun Permohonan'] - X_val_full['year_of_most_sim_rejected_brand_train']\n\nmax_sim_reg_val, year_sim_reg_val = calculate_enriched_similarity_feature_batched(\n    X_val_full, registered_brand_embeddings_train_global, registered_brand_years_train_global, brand_emb_cols, batch_size=BATCH_SIZE_COSINE_SIM\n)\nX_val_full['max_sim_to_registered_brand_train'] = max_sim_reg_val\nX_val_full['year_of_most_sim_registered_brand_train'] = year_sim_reg_val\nX_val_full['year_gap_to_most_sim_registered'] = X_val_full['Tahun Permohonan'] - X_val_full['year_of_most_sim_registered_brand_train']\n\nprint(\"\\nMenghitung fitur kemiripan untuk X_test_full...\")\nmax_sim_test_rej, year_sim_test_rej = calculate_enriched_similarity_feature_batched(\n    X_test_full, rejected_brand_embeddings_train_global, rejected_brand_years_train_global, brand_emb_cols, batch_size=BATCH_SIZE_COSINE_SIM\n)\nX_test_full['max_sim_to_rejected_brand_train'] = max_sim_test_rej\nX_test_full['year_of_most_sim_rejected_brand_train'] = year_sim_test_rej\nX_test_full['year_gap_to_most_sim_rejected'] = X_test_full['Tahun Permohonan'] - X_test_full['year_of_most_sim_rejected_brand_train']\n\nmax_sim_reg_test, year_sim_reg_test = calculate_enriched_similarity_feature_batched(\n    X_test_full, registered_brand_embeddings_train_global, registered_brand_years_train_global, brand_emb_cols, batch_size=BATCH_SIZE_COSINE_SIM\n)\nX_test_full['max_sim_to_registered_brand_train'] = max_sim_reg_test\nX_test_full['year_of_most_sim_registered_brand_train'] = year_sim_reg_test\nX_test_full['year_gap_to_most_sim_registered'] = X_test_full['Tahun Permohonan'] - X_test_full['year_of_most_sim_registered_brand_train']\n\n\nprint(\"Fitur kemiripan yang diperkaya berhasil ditambahkan ke X_train, X_val, dan X_test.\")\n\nprint(f\"\\nShape X_train dengan fitur kemiripan baru: {X_train_full.shape}\")\nprint(f\"Shape X_val dengan fitur kemiripan baru: {X_val_full.shape}\")\nprint(f\"Shape X_test dengan fitur kemiripan baru: {X_test_full.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T13:26:57.453404Z","iopub.execute_input":"2025-07-09T13:26:57.453750Z","iopub.status.idle":"2025-07-09T13:49:07.348646Z","shell.execute_reply.started":"2025-07-09T13:26:57.453730Z","shell.execute_reply":"2025-07-09T13:49:07.347904Z"}},"outputs":[{"name":"stdout","text":"\nShape X_train (loaded): (215965, 823)\nShape X_val (loaded): (54043, 823)\nShape X_test (loaded): (67326, 823)\nShape y_train (loaded): (215965,)\nShape y_val (loaded): (54043,)\nShape y_test (loaded): (67326,)\n\nDitemukan 768 kolom Brand Embeddings (brand_sparse_emb_).\nJumlah sampel 'Ditolak' di set pelatihan global untuk referensi: 57645\nJumlah sampel 'Didaftar' di set pelatihan global untuk referensi: 158320\n\nMenghitung OOF similarity features untuk X_train_df dengan 5-fold CV...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"OOF Folds:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2e0b6f0a7eb4d0cbac916139aaaf983"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Enriched Similarity:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c8a3b852d8c4e7b9d474c95daadf860"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Enriched Similarity:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79ef90f9e41e4c349ffcc4ecbe8465d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Enriched Similarity:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"377cab188e0744dcbb113df8fb4529c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Enriched Similarity:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca1672b8cb524dcd9ce24dde0a31b9ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Enriched Similarity:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a926e81a822242ff967232423cb82f92"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Enriched Similarity:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85bbb59950584b2784651e8baefeb76e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Enriched Similarity:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51249e8570554f1fb1c5064e90a58cae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Enriched Similarity:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2034864b5f0d4b62b43775b60f4bfbde"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Enriched Similarity:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c11bd5c474c44960b5e60740c64e721c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Enriched Similarity:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5bff955cf1c413ca825e54e67cda441"}},"metadata":{}},{"name":"stdout","text":"\nMenghitung fitur kemiripan untuk X_val_full...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Calculating Enriched Similarity:   0%|          | 0/28 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1bbf3aa5edf41a08a8706790149007f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Enriched Similarity:   0%|          | 0/28 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54fcf608902f49628c2647e4a8ac351e"}},"metadata":{}},{"name":"stdout","text":"\nMenghitung fitur kemiripan untuk X_test_full...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Calculating Enriched Similarity:   0%|          | 0/34 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fbd4783126d44809a6dd64d82d77645"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Enriched Similarity:   0%|          | 0/34 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4b4f02251404dee94d6d32e82ce2999"}},"metadata":{}},{"name":"stdout","text":"Fitur kemiripan yang diperkaya berhasil ditambahkan ke X_train, X_val, dan X_test.\n\nShape X_train dengan fitur kemiripan baru: (215965, 829)\nShape X_val dengan fitur kemiripan baru: (54043, 829)\nShape X_test dengan fitur kemiripan baru: (67326, 829)\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# Fungsi pembuatan fitur berdasarkan Kode Kelas yang sudah di OHE.","metadata":{}},{"cell_type":"code","source":"def calculate_class_popularity_risk_features(X_train_df, y_train_series, X_val_df, y_val_series, X_test_df, y_test_series):\n    \"\"\"\n    Menghitung fitur popularitas/risiko kelas (num_rejected, num_registered, rejection_rate)\n    berdasarkan data pelatihan dan menambahkannya ke semua set.\n\n    Args:\n        X_train_df (pd.DataFrame): DataFrame fitur pelatihan.\n        y_train_series (pd.Series): Series target pelatihan.\n        X_val_df (pd.DataFrame): DataFrame fitur validasi.\n        y_val_series (pd.Series): Series target validasi.\n        X_test_df (pd.DataFrame): DataFrame fitur pengujian.\n        y_test_series (pd.Series): Series target pengujian.\n\n    Returns:\n        tuple: (X_train_df, X_val_df, X_test_df) dengan fitur baru ditambahkan.\n    \"\"\"\n    print(\"\\nMemulai perhitungan fitur Popularitas/Risiko Kelas...\")\n\n    kode_kelas_cols = [col for col in X_train_df.columns if col.startswith('Kode_Kelas_')]\n    if not kode_kelas_cols:\n        print(\"Peringatan: Kolom Kode_Kelas_ (OHE) tidak ditemukan. Fitur popularitas/risiko kelas tidak dapat dihitung.\")\n        return X_train_df, X_val_df, X_test_df\n\n    print(\"Menghitung statistik kelas dari data pelatihan...\")\n    \n    train_data_for_class_stats = X_train_df[kode_kelas_cols].copy()\n    train_data_for_class_stats['Status_Encoded'] = y_train_series\n\n    class_stats = {} \n\n    for col in tqdm(kode_kelas_cols, desc=\"Calculating Class Stats\"):\n        class_id = col.replace('Kode_Kelas_', '') \n        \n        df_class_subset = train_data_for_class_stats[train_data_for_class_stats[col] == 1]\n        \n        if not df_class_subset.empty:\n            num_rejected = (df_class_subset['Status_Encoded'] == 0).sum()\n            num_registered = (df_class_subset['Status_Encoded'] == 1).sum()\n            \n            total_in_class = num_rejected + num_registered\n            rejection_rate = num_rejected / total_in_class if total_in_class > 0 else 0.0\n        else:\n            num_rejected = 0\n            num_registered = 0\n            rejection_rate = 0.0 \n\n        class_stats[class_id] = {\n            'num_rejected': num_rejected,\n            'num_registered': num_registered,\n            'rejection_rate': rejection_rate\n        }\n    \n    del train_data_for_class_stats\n    gc.collect()\n    print(\"Statistik kelas berhasil dihitung.\")\n\n    print(\"\\nMenambahkan fitur popularitas/risiko kelas ke semua set...\")\n\n  \n    def add_class_features_to_df(df_target, class_stats_dict, kode_kelas_cols):\n        df_target_copy = df_target.copy() \n        \n        df_target_copy['num_rejected_in_class_train'] = 0.0 \n        df_target_copy['num_registered_in_class_train'] = 0.0\n        df_target_copy['rejection_rate_in_class_train'] = 0.0\n        \n        for index, row in tqdm(df_target_copy.iterrows(), total=len(df_target_copy), desc=\"Adding Class Features\"):\n            active_classes = [col.replace('Kode_Kelas_', '') for col in kode_kelas_cols if row[col] == 1]\n            \n            if active_classes:\n                main_class_id = active_classes[0] \n                stats = class_stats_dict.get(main_class_id, {'num_rejected': 0, 'num_registered': 0, 'rejection_rate': 0.0})\n                \n                df_target_copy.loc[index, 'num_rejected_in_class_train'] = stats['num_rejected']\n                df_target_copy.loc[index, 'num_registered_in_class_train'] = stats['num_registered']\n                df_target_copy.loc[index, 'rejection_rate_in_class_train'] = stats['rejection_rate']\n            else:\n                pass\n        \n        df_target_copy['num_rejected_in_class_train'] = df_target_copy['num_rejected_in_class_train'].astype(np.float32)\n        df_target_copy['num_registered_in_class_train'] = df_target_copy['num_registered_in_class_train'].astype(np.float32)\n        df_target_copy['rejection_rate_in_class_train'] = df_target_copy['rejection_rate_in_class_train'].astype(np.float32)\n\n        return df_target_copy\n\n    X_train_df = add_class_features_to_df(X_train_df, class_stats, kode_kelas_cols)\n    X_val_df = add_class_features_to_df(X_val_df, class_stats, kode_kelas_cols)\n    X_test_df = add_class_features_to_df(X_test_df, class_stats, kode_kelas_cols)\n\n    print(\"Fitur Popularitas/Risiko Kelas berhasil ditambahkan.\")\n    print(\"Contoh kolom baru di X_train_df (head):\\n\", X_train_df[['num_rejected_in_class_train', 'num_registered_in_class_train', 'rejection_rate_in_class_train']].head())\n\n    return X_train_df, X_val_df, X_test_df\n\n\nX_train_full, X_val_full, X_test_full = calculate_class_popularity_risk_features(\n    X_train_full, y_train_full, X_val_full, y_val_full, X_test_full, y_test_full\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T13:53:43.917641Z","iopub.execute_input":"2025-07-09T13:53:43.918292Z","iopub.status.idle":"2025-07-09T14:18:46.113170Z","execution_failed":"2025-07-09T16:13:00.797Z"}},"outputs":[{"name":"stdout","text":"\nMemulai perhitungan fitur Popularitas/Risiko Kelas...\nMenghitung statistik kelas dari data pelatihan...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Calculating Class Stats:   0%|          | 0/46 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42cc9b2eea184eb1ac20f15a2c8d7454"}},"metadata":{}},{"name":"stdout","text":"Statistik kelas berhasil dihitung.\n\nMenambahkan fitur popularitas/risiko kelas ke semua set...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Adding Class Features:   0%|          | 0/215965 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3883d4d25ec415685d9c6da0183095f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Adding Class Features:   0%|          | 0/54043 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d173a1c655b42c88d55b1fb8b387210"}},"metadata":{}},{"name":"stdout","text":"Fitur Popularitas/Risiko Kelas berhasil ditambahkan.\nContoh kolom baru di X_train_df (head):\n    num_rejected_in_class_train  num_registered_in_class_train  \\\n0                       7976.0                        15063.0   \n1                        862.0                         3193.0   \n2                       7976.0                        15063.0   \n3                       1456.0                         5379.0   \n4                        862.0                         3193.0   \n\n   rejection_rate_in_class_train  \n0                       0.346196  \n1                       0.212577  \n2                       0.346196  \n3                       0.213021  \n4                       0.212577  \n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"# Logging Experiments","metadata":{}},{"cell_type":"code","source":"import mlflow\nimport mlflow.catboost\nimport mlflow.lightgbm\nimport shap\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport io \nimport pandas as pd \nimport numpy as np \nimport catboost as cb\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n\n\n# # Skenario 1: Model dengan Text (Dense) Embeddings + Fitur Tabular + Fitur-fitur Retrieval\n# CURRENT_EMBEDDING_MODEL = 'intfloat/multilingual-e5-large-instruct'\n# CURRENT_IMAGE_EMBEDDING_MODEL = 'N/A (Tabular + Text Only)'\n# FEATURES_USED_DESCRIPTION = \"Tahun Permohonan + Kode Kelas (OHE) + Brand Embeddings + Deskripsi Kelas Embeddings + Retrieval\"\n# MODEL_ARTIFACT_NAME = \"trademark_catboost_text_iks\"\n# CLASSIFIER_TYPE = \"CatBoost\"\n# features_for_scenario = ['Tahun Permohonan'] + [col for col in X_train_full.columns if col.startswith('Kode_Kelas_')] + \\\n#                         [col for col in X_train_full.columns if col.startswith('brand_emb_')] + \\\n#                         ['max_sim_to_rejected_brand_train',\t'year_of_most_sim_rejected_brand_train',\t'max_sim_to_registered_brand_train'\t,'year_of_most_sim_registered_brand_train',\t'year_gap_to_most_sim_rejected',\t'year_gap_to_most_sim_registered'\t,'num_rejected_in_class_train',\t'num_registered_in_class_train',\t'rejection_rate_in_class_train'] # Pastikan fitur ini sudah ada di X_train_full\n                        \n# X_train_scenario = X_train_full[features_for_scenario]\n# X_val_scenario = X_val_full[features_for_scenario]\n# X_test_scenario = X_test_full[features_for_scenario]\n# print(X_train_scenario.shape) \n# print(X_val_scenario.shape )\n# print(X_test_scenario.shape )\n# cat_clf = cb.CatBoostClassifier(objective='Logloss', random_seed=42, verbose=0, eval_metric='F1',  early_stopping_rounds=50)\n# cat_clf.fit(X_train_scenario, y_train_full, eval_set=(X_val_scenario, y_val_full))\n\n\n# # Skenario 2: Model dengan Text Embeddings (Sparse) + Fitur Tabular + Fitur-fitur Retrieval\n# CURRENT_EMBEDDING_MODEL = 'opensearch-project/opensearch-neural-sparse-encoding-multilingual-v1'\n# CURRENT_IMAGE_EMBEDDING_MODEL = 'N/A (Tabular + Text Only)'\n# FEATURES_USED_DESCRIPTION = \"Tahun Permohonan + Kode Kelas (OHE) + Brand Embeddings + Deskripsi Kelas Embeddings + Retrieval\"\n# MODEL_ARTIFACT_NAME = \"trademark_catboost_text_iks\"\n# CLASSIFIER_TYPE = \"CatBoost\"\n# features_for_scenario = ['Tahun Permohonan'] + [col for col in X_train_full.columns if col.startswith('Kode_Kelas_')] + \\\n#                         [col for col in X_train_full.columns if col.startswith('brand_sparse_emb_')] + \\\n#                         ['max_sim_to_rejected_brand_train',\t'year_of_most_sim_rejected_brand_train',\t'max_sim_to_registered_brand_train'\t,'year_of_most_sim_registered_brand_train',\t'year_gap_to_most_sim_rejected',\t'year_gap_to_most_sim_registered'\t,'num_rejected_in_class_train',\t'num_registered_in_class_train',\t'rejection_rate_in_class_train'] # Pastikan fitur ini sudah ada di X_train_full\n                        \n# X_train_scenario = X_train_full[features_for_scenario]\n# X_val_scenario = X_val_full[features_for_scenario]\n# X_test_scenario = X_test_full[features_for_scenario]\n# print(X_train_scenario.shape) \n# print(X_val_scenario.shape )\n# print(X_test_scenario.shape )\n# cat_clf = cb.CatBoostClassifier(objective='Logloss', random_seed=42, verbose=0, eval_metric='F1',  early_stopping_rounds=75)\n# cat_clf.fit(X_train_scenario, y_train_full, eval_set=(X_val_scenario, y_val_full))\n\n# Skenario 3: Model dengan Text Embeddings + Fitur Tabular + Indeks Konflik Semantik (IKS)\nCURRENT_EMBEDDING_MODEL = 'intfloat/multilingual-e5-large-instruct'\nRUN_NAME = \"CatBoost_Ablation_03_TextEmbeddings_IKS_Tabular\"\nCURRENT_IMAGE_EMBEDDING_MODEL = 'N/A (Tabular + Text Only)'\nFEATURES_USED_DESCRIPTION = \"Tahun Permohonan + Kode Kelas (OHE) + Brand Embeddings + Deskripsi Kelas Embeddings + IKS\"\nMODEL_ARTIFACT_NAME = \"trademark_catboost_text_iks\"\nCLASSIFIER_TYPE = \"CatBoost\"\nfeatures_for_scenario = ['Tahun Permohonan'] + \\\n                        [col for col in X_train_full.columns if col.startswith('image_emb_')] + \\\n                        ['max_sim_to_rejected_logo_train','year_of_most_sim_rejected_logo_train','max_sim_to_registered_logo_train','year_of_most_sim_registered_logo_train', 'year_gap_to_most_sim_rejected_logo', 'year_gap_to_most_sim_registered_logo'] \n                        \nX_train_scenario = X_train_full[features_for_scenario]\nX_val_scenario = X_val_full[features_for_scenario]\nX_test_scenario = X_test_full[features_for_scenario]\nprint(X_train_scenario.shape) \nprint(X_val_scenario.shape )\nprint(X_test_scenario.shape )\ncat_clf = cb.CatBoostClassifier(objective='Logloss', random_seed=42, verbose=0, eval_metric='F1',  early_stopping_rounds=75)\ncat_clf.fit(X_train_scenario, y_train_full, eval_set=(X_val_scenario, y_val_full))\n\n\nif not os.path.exists(\"mlruns\"):\n    os.makedirs(\"mlruns\")\n\nwith mlflow.start_run(run_name=RUN_NAME) as run:\n    run_id = run.info.run_id\n    print(f\"\\nMLflow Run ID: {run_id}\")\n\n    mlflow.log_param(\"embedding_model_text\", CURRENT_EMBEDDING_MODEL) \n    mlflow.log_param(\"embedding_model_image\", CURRENT_IMAGE_EMBEDDING_MODEL) \n    mlflow.log_param(\"features_used\", FEATURES_USED_DESCRIPTION)\n    mlflow.log_param(\"classifier\", CLASSIFIER_TYPE)\n    mlflow.log_param(\"class_imbalance_handling\", \"auto_class_weights='Balanced'\") \n    mlflow.log_param(\"random_state\", 42)\n\n\n    if CLASSIFIER_TYPE == \"CatBoost\":\n        y_pred_test = cat_clf.predict(X_test_scenario) \n        y_pred_proba_test = cat_clf.predict_proba(X_test_scenario)[:, 1]\n    elif CLASSIFIER_TYPE == \"LightGBM\":\n        y_pred_test = lgb_clf.predict(X_test_scenario) \n        y_pred_proba_test = lgb_clf.predict_proba(X_test_scenario)[:, 1]\n\n    accuracy_test = accuracy_score(y_test_full, y_pred_test)\n    precision_test = precision_score(y_test_full, y_pred_test)\n    recall_test = recall_score(y_test_full, y_pred_test)\n    f1_test = f1_score(y_test_full, y_pred_test)\n    roc_auc_test = roc_auc_score(y_test_full, y_pred_proba_test)\n\n    mlflow.log_metric(\"accuracy_test\", accuracy_test)\n    mlflow.log_metric(\"precision_test\", precision_test)\n    mlflow.log_metric(\"recall_test\", recall_test)\n    mlflow.log_metric(\"f1_score_test\", f1_test)\n    mlflow.log_metric(\"roc_auc_test\", roc_auc_test)\n\n    print(f\"Accuracy (Test): {accuracy_test:.4f}\")\n    print(f\"F1 Score (Test): {f1_test:.4f}\")\n    print(f\"ROC AUC (Test): {roc_auc_test:.4f}\")\n    \n    y_pred_val = cat_clf.predict(X_val_scenario)\n    y_pred_proba_val = cat_clf.predict_proba(X_val_scenario)[:, 1]\n\n    accuracy_val = accuracy_score(y_val_full, y_pred_val)\n    precision_val = precision_score(y_val_full, y_pred_val)\n    recall_val = recall_score(y_val_full, y_pred_val)\n    f1_val = f1_score(y_val_full, y_pred_val)\n    roc_auc_val = roc_auc_score(y_val_full, y_pred_proba_val)\n\n    mlflow.log_metric(\"accuracy_val\", accuracy_val)\n    mlflow.log_metric(\"precision_val\", precision_val)\n    mlflow.log_metric(\"recall_val\", recall_val)\n    mlflow.log_metric(\"f1_score_val\", f1_val)\n    mlflow.log_metric(\"roc_auc_val\", roc_auc_val)\n\n    print(f\"Accuracy (Validation): {accuracy_val:.4f}\")\n    print(f\"F1 Score (Validation): {f1_val:.4f}\")\n    print(f\"ROC AUC (Validation): {roc_auc_val:.4f}\")\n\n    cm_test = confusion_matrix(y_test_full, y_pred_test)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm_test, annot=True, fmt='d', cmap='Blues', xticklabels=['Ditolak', 'Didaftar'], yticklabels=['Ditolak', 'Didaftar'])\n    plt.xlabel('Predicted')\n    plt.ylabel('Actual')\n    plt.title(f'Confusion Matrix (Test) - {RUN_NAME}')\n    plt.savefig(\"confusion_matrix_test.png\")\n    mlflow.log_artifact(\"confusion_matrix_test.png\")\n    plt.close()\n    \n    cm_val = confusion_matrix(y_val_full, y_pred_val)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm_val, annot=True, fmt='d', cmap='Blues', xticklabels=['Ditolak', 'Didaftar'], yticklabels=['Ditolak', 'Didaftar'])\n    plt.xlabel('Predicted')\n    plt.ylabel('Actual')\n    plt.title(f'Confusion Matrix (Validation) - {RUN_NAME}')\n    plt.savefig(\"confusion_matrix_val.png\")\n    mlflow.log_artifact(\"confusion_matrix_val.png\")\n    plt.close()\n\n    print(\"Menghitung SHAP values...\")\n    explainer = shap.TreeExplainer(cat_clf)\n    \n    X_test_for_shap = X_test_scenario.sample(n=min(7000, len(X_test_scenario)), random_state=42)\n    shap_values = explainer.shap_values(X_test_for_shap)\n\n    plt.figure(figsize=(10, 6))\n    shap.summary_plot(shap_values, X_test_for_shap, show=False) \n    plt.title(f\"SHAP Summary Plot - {RUN_NAME}\")\n    plt.tight_layout()\n    plt.savefig(\"shap_summary_plot.png\")\n    mlflow.log_artifact(\"shap_summary_plot.png\")\n    plt.close()\n\n    if 'Tahun Permohonan' in X_test_for_shap.columns:\n        plt.figure(figsize=(8, 6))\n        shap.dependence_plot(\"Tahun Permohonan\", shap_values, X_test_for_shap, show=False)\n        plt.title(f\"SHAP Dependence Plot - Tahun Permohonan ({RUN_NAME})\")\n        plt.tight_layout()\n        plt.savefig(\"shap_dependence_plot_tahun_permohonan.png\")\n        mlflow.log_artifact(\"shap_dependence_plot_tahun_permohonan.png\")\n        plt.close()\n    \n    if 'max_sim_to_rejected_brand_train' in X_test_for_shap.columns:\n        plt.figure(figsize=(8, 6))\n        shap.dependence_plot(\"max_sim_to_rejected_brand_train\", shap_values, X_test_for_shap, show=False)\n        plt.title(f\"SHAP Dependence Plot - IKS ({RUN_NAME})\")\n        plt.tight_layout()\n        plt.savefig(\"shap_dependence_plot_iks.png\")\n        mlflow.log_artifact(\"shap_dependence_plot_iks.png\")\n        plt.close()\n\n\n    feature_importance = pd.DataFrame({\n        'feature': X_train_scenario.columns,\n        'importance': cat_clf.feature_importances_\n    }).sort_values(by='importance', ascending=False)\n        \n    mlflow.log_text(feature_importance.to_csv(index=False), \"feature_importance.csv\")\n    print(\"\\nFeature Importance dilog ke MLflow.\")\n\n    mlflow.catboost.log_model(\n        cb_model=cat_clf,\n        artifact_path=MODEL_ARTIFACT_NAME,\n        input_example=X_train_scenario.head(1)\n    )\n    print(f\"\\nModel {MODEL_ARTIFACT_NAME} dilog ke MLflow.\")\n\nprint(\"\\nMLflow Run completed\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T03:18:59.025293Z","iopub.execute_input":"2025-07-10T03:18:59.025982Z","iopub.status.idle":"2025-07-10T03:19:54.133731Z","shell.execute_reply.started":"2025-07-10T03:18:59.025959Z","shell.execute_reply":"2025-07-10T03:19:54.133033Z"}},"outputs":[{"name":"stdout","text":"(52789, 1031)\n(13134, 1031)\n(16160, 1031)\n","output_type":"stream"},{"name":"stderr","text":"2025/07/10 03:19:23 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n2025/07/10 03:19:23 INFO mlflow.store.db.utils: Updating database tables\nINFO  [alembic.runtime.migration] Context impl SQLiteImpl.\nINFO  [alembic.runtime.migration] Will assume non-transactional DDL.\nINFO  [alembic.runtime.migration] Running upgrade  -> 451aebb31d03, add metric step\nINFO  [alembic.runtime.migration] Running upgrade 451aebb31d03 -> 90e64c465722, migrate user column to tags\nINFO  [alembic.runtime.migration] Running upgrade 90e64c465722 -> 181f10493468, allow nulls for metric values\nINFO  [alembic.runtime.migration] Running upgrade 181f10493468 -> df50e92ffc5e, Add Experiment Tags Table\nINFO  [alembic.runtime.migration] Running upgrade df50e92ffc5e -> 7ac759974ad8, Update run tags with larger limit\nINFO  [alembic.runtime.migration] Running upgrade 7ac759974ad8 -> 89d4b8295536, create latest metrics table\nINFO  [89d4b8295536_create_latest_metrics_table_py] Migration complete!\nINFO  [alembic.runtime.migration] Running upgrade 89d4b8295536 -> 2b4d017a5e9b, add model registry tables to db\nINFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Adding registered_models and model_versions tables to database.\nINFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Migration complete!\nINFO  [alembic.runtime.migration] Running upgrade 2b4d017a5e9b -> cfd24bdc0731, Update run status constraint with killed\nINFO  [alembic.runtime.migration] Running upgrade cfd24bdc0731 -> 0a8213491aaa, drop_duplicate_killed_constraint\nINFO  [alembic.runtime.migration] Running upgrade 0a8213491aaa -> 728d730b5ebd, add registered model tags table\nINFO  [alembic.runtime.migration] Running upgrade 728d730b5ebd -> 27a6a02d2cf1, add model version tags table\nINFO  [alembic.runtime.migration] Running upgrade 27a6a02d2cf1 -> 84291f40a231, add run_link to model_version\nINFO  [alembic.runtime.migration] Running upgrade 84291f40a231 -> a8c4a736bde6, allow nulls for run_id\nINFO  [alembic.runtime.migration] Running upgrade a8c4a736bde6 -> 39d1c3be5f05, add_is_nan_constraint_for_metrics_tables_if_necessary\nINFO  [alembic.runtime.migration] Running upgrade 39d1c3be5f05 -> c48cb773bb87, reset_default_value_for_is_nan_in_metrics_table_for_mysql\nINFO  [alembic.runtime.migration] Running upgrade c48cb773bb87 -> bd07f7e963c5, create index on run_uuid\nINFO  [alembic.runtime.migration] Running upgrade bd07f7e963c5 -> 0c779009ac13, add deleted_time field to runs table\nINFO  [alembic.runtime.migration] Running upgrade 0c779009ac13 -> cc1f77228345, change param value length to 500\nINFO  [alembic.runtime.migration] Running upgrade cc1f77228345 -> 97727af70f4d, Add creation_time and last_update_time to experiments table\nINFO  [alembic.runtime.migration] Running upgrade 97727af70f4d -> 3500859a5d39, Add Model Aliases table\nINFO  [alembic.runtime.migration] Running upgrade 3500859a5d39 -> 7f2a7d5fae7d, add datasets inputs input_tags tables\nINFO  [alembic.runtime.migration] Running upgrade 7f2a7d5fae7d -> 2d6e25af4d3e, increase max param val length from 500 to 8000\nINFO  [alembic.runtime.migration] Running upgrade 2d6e25af4d3e -> acf3f17fdcc7, add storage location field to model versions\nINFO  [alembic.runtime.migration] Running upgrade acf3f17fdcc7 -> 867495a8f9d4, add trace tables\nINFO  [alembic.runtime.migration] Running upgrade 867495a8f9d4 -> 5b0e9adcef9c, add cascade deletion to trace tables foreign keys\nINFO  [alembic.runtime.migration] Running upgrade 5b0e9adcef9c -> 4465047574b1, increase max dataset schema size\nINFO  [alembic.runtime.migration] Running upgrade 4465047574b1 -> f5a4f2784254, increase run tag value limit to 8000\nINFO  [alembic.runtime.migration] Running upgrade f5a4f2784254 -> 0584bdc529eb, add cascading deletion to datasets from experiments\nINFO  [alembic.runtime.migration] Running upgrade 0584bdc529eb -> 400f98739977, add logged model tables\nINFO  [alembic.runtime.migration] Running upgrade 400f98739977 -> 6953534de441, add step to inputs table\nINFO  [alembic.runtime.migration] Running upgrade 6953534de441 -> bda7b8c39065, increase_model_version_tag_value_limit\nINFO  [alembic.runtime.migration] Context impl SQLiteImpl.\nINFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n","output_type":"stream"},{"name":"stdout","text":"\nMLflow Run ID: 371f24c0876c42c2837fb56d0e9bc6b3\nAccuracy (Test): 0.8256\nF1 Score (Test): 0.9039\nROC AUC (Test): 0.5471\nAccuracy (Validation): 0.8310\nF1 Score (Validation): 0.9073\nROC AUC (Validation): 0.5397\nMenghitung SHAP values...\n","output_type":"stream"},{"name":"stderr","text":"The figure layout has changed to tight\n2025/07/10 03:19:36 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n","output_type":"stream"},{"name":"stdout","text":"\nFeature Importance dilog ke MLflow.\n","output_type":"stream"},{"name":"stderr","text":"Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n","output_type":"stream"},{"name":"stdout","text":"\nModel trademark_catboost_text_iks dilog ke MLflow.\n\nMLflow Run completed\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 0 Axes>"},"metadata":{}}],"execution_count":19},{"cell_type":"markdown","source":"# Penyimpanan trained model dalam format CBM","metadata":{}},{"cell_type":"code","source":"import os\n\nmodel_save_dir = '/kaggle/working/' \nos.makedirs(model_save_dir, exist_ok=True) \n\nmodel_filename_cbm = 'trademark_catboost_model_textdense.cbm'\nmodel_save_path_cbm = os.path.join(model_save_dir, model_filename_cbm)\n\nprint(f\"\\nMenyimpan model CatBoost ke: {model_save_path_cbm} (format .cbm)\")\ntry:\n    cat_clf.save_model(model_save_path_cbm)\n    print(\"Model CatBoost berhasil disimpan dalam format .cbm.\")\n    print(f\"Anda dapat menemukan model ini di panel 'Files' Kaggle/Colab di folder '{model_save_dir}'.\")\nexcept Exception as e:\n    print(f\"Gagal menyimpan model ke .cbm: {e}\")\n\n\nfrom catboost import CatBoostClassifier \n\nprint(f\"\\nMemuat kembali model CatBoost dari: {model_save_path_cbm} (format .cbm)\")\ntry:\n    loaded_cat_clf_cbm = CatBoostClassifier() \n    loaded_cat_clf_cbm.load_model(model_save_path_cbm) \n    print(\"Model CatBoost berhasil dimuat kembali dari .cbm.\")\n\n    if 'X_test' in locals() and 'y_test' in locals():\n        from sklearn.metrics import accuracy_score \n        loaded_y_pred_cbm = loaded_cat_clf_cbm.predict(X_test)\n        loaded_accuracy_cbm = accuracy_score(y_test, loaded_y_pred_cbm)\n        print(f\"Akurasi model yang dimuat dari .cbm: {loaded_accuracy_cbm:.4f}\")\n    else:\n        print(\"X_test dan y_test tidak tersedia untuk verifikasi akurasi.\")\n\nexcept FileNotFoundError:\n    print(f\"Error: File model .cbm tidak ditemukan di '{model_save_path_cbm}'.\")\n    print(\"Pastikan Anda sudah menyimpan model di sesi ini atau mengunggahnya ke direktori yang benar.\")\nexcept Exception as e:\n    print(f\"Gagal memuat model dari .cbm: {e}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T03:23:06.991311Z","iopub.execute_input":"2025-07-10T03:23:06.991614Z","iopub.status.idle":"2025-07-10T03:23:07.006549Z","shell.execute_reply.started":"2025-07-10T03:23:06.991595Z","shell.execute_reply":"2025-07-10T03:23:07.005901Z"}},"outputs":[{"name":"stdout","text":"\nMenyimpan model CatBoost ke: /kaggle/working/trademark_catboost_model_textdense.cbm (format .cbm)\nModel CatBoost berhasil disimpan dalam format .cbm.\nAnda dapat menemukan model ini di panel 'Files' Kaggle/Colab di folder '/kaggle/working/'.\n\nMemuat kembali model CatBoost dari: /kaggle/working/trademark_catboost_model_textdense.cbm (format .cbm)\nModel CatBoost berhasil dimuat kembali dari .cbm.\nX_test dan y_test tidak tersedia untuk verifikasi akurasi.\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np \n\ndef normalize_logo_file_paths(df_target):\n    \"\"\"\n    Mengubah semua backslash '\\' menjadi forward slash '/' di kolom 'Logo File'\n    dari DataFrame yang diberikan.\n\n    Args:\n        df_target (pd.DataFrame): DataFrame yang akan dimodifikasi (misal X_train_full).\n\n    Returns:\n        pd.DataFrame: DataFrame dengan jalur file logo yang dinormalisasi.\n    \"\"\"\n    if 'Logo File' not in df_target.columns:\n        print(\"Peringatan: Kolom 'Logo File' tidak ditemukan di DataFrame. Tidak ada normalisasi jalur file yang dilakukan.\")\n        return df_target.copy() \n\n    df_modified = df_target.copy() \n\n    print(\"\\nMemulai normalisasi jalur file di kolom 'Logo File'...\")\n    df_modified['Logo File'] = df_modified['Logo File'].apply(\n        lambda x: str(x).replace('\\\\', '/') if pd.notna(x) else x\n    )\n    print(\"Normalisasi jalur file selesai.\")\n    return df_modified\n\nprint(\"Shape X_train_full sebelum normalisasi path:\", X_train_full.shape)\nprint(\"Shape X_val_full sebelum normalisasi path:\", X_val_full.shape)\nprint(\"Shape X_test_full sebelum normalisasi path:\", X_test_full.shape)\n\nX_train_full = normalize_logo_file_paths(X_train_full)\nX_val_full = normalize_logo_file_paths(X_val_full)\nX_test_full = normalize_logo_file_paths(X_test_full)\n\nprint(\"\\nNormalisasi jalur file 'Logo File' selesai untuk semua split dataset.\")\nprint(X_train_full['Logo File'].head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T01:15:02.340566Z","iopub.execute_input":"2025-07-10T01:15:02.340838Z","iopub.status.idle":"2025-07-10T01:15:02.602538Z","shell.execute_reply.started":"2025-07-10T01:15:02.340818Z","shell.execute_reply":"2025-07-10T01:15:02.601723Z"}},"outputs":[{"name":"stdout","text":"Shape X_train_full sebelum normalisasi path: (215965, 55)\nShape X_val_full sebelum normalisasi path: (54043, 55)\nShape X_test_full sebelum normalisasi path: (67326, 55)\n\nMemulai normalisasi jalur file di kolom 'Logo File'...\nNormalisasi jalur file selesai.\n\nMemulai normalisasi jalur file di kolom 'Logo File'...\nNormalisasi jalur file selesai.\n\nMemulai normalisasi jalur file di kolom 'Logo File'...\nNormalisasi jalur file selesai.\n\nNormalisasi jalur file 'Logo File' selesai untuk semua split dataset.\n0    NaN\n1    NaN\n2    NaN\n3    NaN\n4    NaN\nName: Logo File, dtype: object\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import pandas as pd\nimport os\nfrom PIL import Image\nimport torch\nfrom transformers import AutoImageProcessor, AutoModel\nfrom tqdm.notebook import tqdm \n\n\nbase_dir_ditolak = '/kaggle/input/dataset-pdki-aplikasi-merek/dataset_logo_pdki_Ditolak/'\nbase_dir_didaftar = '/kaggle/input/dataset-pdki-aplikasi-merek/dataset_logo_pdki_Didaftar/'\n\nprint(\"Jumlah baris sebelum menghapus NaN:\")\nprint(f\"X_train_full: {len(X_train_full)} baris\")\nprint(f\"X_test_full: {len(X_test_full)} baris\")\nprint(f\"X_val_full: {len(X_val_full)} baris\")\n\nX_train_full = X_train_full.dropna(subset=['Logo File']).reset_index(drop=True)\nX_test_full = X_test_full.dropna(subset=['Logo File']).reset_index(drop=True)\nX_val_full = X_val_full.dropna(subset=['Logo File']).reset_index(drop=True)\n\nprint(\"\\nJumlah baris setelah menghapus NaN:\")\nprint(f\"X_train_full: {len(X_train_full)} baris\")\nprint(f\"X_test_full: {len(X_test_full)} baris\")\nprint(f\"X_val_full: {len(X_val_full)} baris\")\n\nprint(\"\\nMemuat model DINOv2 'facebook/dinov2-with-registers-large'...\")\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Menggunakan perangkat: {device}\")\n\nprocessor = AutoImageProcessor.from_pretrained('facebook/dinov2-with-registers-large')\nmodel = AutoModel.from_pretrained('facebook/dinov2-with-registers-large').to(device)\nmodel.eval() \n\nEMBEDDING_DIM = 1024\nZERO_VECTOR = torch.zeros(EMBEDDING_DIM).cpu().numpy()\n\nall_logo_files = pd.concat([\n    X_train_full['Logo File'],\n    X_test_full['Logo File'],\n    X_val_full['Logo File']\n]).unique()\n\nimage_embeddings_cache = {}\nBATCH_SIZE = 32 \nprint(f\"\\nMemproses {len(all_logo_files)} gambar unik dalam batch {BATCH_SIZE}...\")\n\ndef find_image_full_path(relative_path):\n    \"\"\"Mencari jalur lengkap gambar di direktori ditolak atau didaftar.\"\"\"\n    path_ditolak = os.path.join(base_dir_ditolak, relative_path)\n    if os.path.exists(path_ditolak):\n        return path_ditolak\n    path_didaftar = os.path.join(base_dir_didaftar, relative_path)\n    if os.path.exists(path_didaftar):\n        return path_didaftar\n    return None\n\nfor i in tqdm(range(0, len(all_logo_files), BATCH_SIZE), desc=\"Menghasilkan embedding gambar\"):\n    batch_paths_relative = all_logo_files[i:i + BATCH_SIZE]\n    \n    images_to_process = []\n    original_paths_in_batch = []\n    \n    for rel_path in batch_paths_relative:\n        full_path = find_image_full_path(rel_path)\n        if full_path:\n            try:\n               \n                img = Image.open(full_path).convert(\"RGB\")\n                images_to_process.append(img)\n                original_paths_in_batch.append(rel_path)\n            except Exception as e:\n                print(f\"Peringatan: Gagal memuat gambar {full_path}: {e}. Menggunakan vektor nol.\")\n                image_embeddings_cache[rel_path] = ZERO_VECTOR\n        else:\n            image_embeddings_cache[rel_path] = ZERO_VECTOR\n            \n    if images_to_process:\n        inputs = processor(images=images_to_process, return_tensors=\"pt\").to(device)\n        with torch.no_grad():\n            outputs = model(**inputs)\n        \n        embeddings = outputs.pooler_output.cpu().numpy()\n        \n        for j, rel_path in enumerate(original_paths_in_batch):\n            image_embeddings_cache[rel_path] = embeddings[j]\n\nprint(\"\\nSelesai menghasilkan embedding gambar.\")\n\nprint(\"\\nMenambahkan kolom 'image_embedding' ke DataFrames...\")\n\ndef add_embeddings_to_df(df, cache):\n    \"\"\"Menambahkan kolom 'image_embedding' ke DataFrame menggunakan cache.\"\"\"\n    df.loc[:, 'image_embedding'] = df['Logo File'].apply(lambda x: cache.get(x, ZERO_VECTOR))\n    return df\n\nX_train_full = add_embeddings_to_df(X_train_full, image_embeddings_cache)\nX_test_full = add_embeddings_to_df(X_test_full, image_embeddings_cache)\nX_val_full = add_embeddings_to_df(X_val_full, image_embeddings_cache)\n\nprint(\"\\nDataFrames setelah penambahan embedding:\")\nprint(\"X_train_full head:\")\nprint(X_train_full.head())\nprint(\"\\nX_test_full head:\")\nprint(X_test_full.head())\nprint(\"\\nX_val_full head:\")\nprint(X_val_full.head())\n\nif not X_train_full.empty:\n    print(f\"\\nDimensi embedding untuk X_train_full: {X_train_full['image_embedding'].iloc[0].shape}\")\nif not X_test_full.empty:\n    print(f\"Dimensi embedding untuk X_test_full: {X_test_full['image_embedding'].iloc[0].shape}\")\nif not X_val_full.empty:\n    print(f\"Dimensi embedding untuk X_val_full: {X_val_full['image_embedding'].iloc[0].shape}\")\n\nprint(\"\\nProses embedding gambar selesai sepenuhnya.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T01:15:28.683957Z","iopub.execute_input":"2025-07-10T01:15:28.684200Z","iopub.status.idle":"2025-07-10T02:50:59.929089Z","shell.execute_reply.started":"2025-07-10T01:15:28.684184Z","shell.execute_reply":"2025-07-10T02:50:59.928403Z"}},"outputs":[{"name":"stderr","text":"2025-07-10 01:15:37.014593: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1752110137.365829      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1752110137.465636      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Jumlah baris sebelum menghapus NaN:\nX_train_full: 215965 baris\nX_test_full: 67326 baris\nX_val_full: 54043 baris\n\nJumlah baris setelah menghapus NaN:\nX_train_full: 52789 baris\nX_test_full: 16160 baris\nX_val_full: 13134 baris\n\nMemuat model DINOv2 'facebook/dinov2-with-registers-large'...\nMenggunakan perangkat: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/436 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a59b1724ec6471886a31b7d7dbc3579"}},"metadata":{}},{"name":"stderr","text":"Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea3b2b2ba8d842658871bb965db03a74"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.22G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9eb1197a21ef40d28ba2ce639a010105"}},"metadata":{}},{"name":"stdout","text":"\nMemproses 80984 gambar unik dalam batch 32...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Menghasilkan embedding gambar:   0%|          | 0/2531 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f33f7c6d3e244bab5f17b4a3bf301ed"}},"metadata":{}},{"name":"stdout","text":"\nSelesai menghasilkan embedding gambar.\n\nMenambahkan kolom 'image_embedding' ke DataFrames...\n\nDataFrames setelah penambahan embedding:\nX_train_full head:\n   Tahun Permohonan  Kode_Kelas_1.0  Kode_Kelas_2.0  Kode_Kelas_3.0  \\\n0              2020           False           False            True   \n1              2022           False           False           False   \n2              2020           False           False            True   \n3              2022           False           False           False   \n4              2022           False           False           False   \n\n   Kode_Kelas_4.0  Kode_Kelas_5.0  Kode_Kelas_6.0  Kode_Kelas_7.0  \\\n0           False           False           False           False   \n1           False           False           False           False   \n2           False           False           False           False   \n3           False           False           False           False   \n4           False           False           False           False   \n\n   Kode_Kelas_8.0  Kode_Kelas_9.0  ...  Kode_Kelas_99.0  \\\n0           False           False  ...            False   \n1           False           False  ...            False   \n2           False           False  ...            False   \n3           False           False  ...            False   \n4           False           False  ...            False   \n\n                    Brand                     Logo File  Status_Encoded  \\\n0    natucoco + lukisan /  logos_2020/DID2020008379.jpg               1   \n1  voila brow dan logo vb  logos_2022/JID2022024980.jpg               0   \n2              clean look  logos_2020/DID2020069641.jpg               1   \n3                kopioren  logos_2022/JID2022015471.jpg               1   \n4                 capella  logos_2022/JID2022052066.jpg               1   \n\n            Nama Pemilik  Nomor Permohonan  Nama Pemilik_normalized  \\\n0  CV. AGRO JAVA MANDIRI     DID2020008379     cv_agro_java_mandiri   \n1         FELISCA TASLIM     JID2022024980           felisca_taslim   \n2         DWI RAKHMAWATI     DID2020069641           dwi_rakhmawati   \n3           FRANS ATMAJA     JID2022015471             frans_atmaja   \n4      PT. CAPELLA MEDAN     JID2022052066         pt_capella_medan   \n\n                           Brand_Owner_Group  Split_Type  \\\n0  natucoco + lukisan /_cv_agro_java_mandiri       train   \n1      voila brow dan logo vb_felisca_taslim       train   \n2                  clean look_dwi_rakhmawati       train   \n3                      kopioren_frans_atmaja       train   \n4                   capella_pt_capella_medan       train   \n\n                                     image_embedding  \n0  [-0.6248816, 0.96178836, -0.6451885, 0.1405979...  \n1  [-0.066583455, 1.0164951, -0.3532108, 0.723336...  \n2  [0.6826305, 0.5323672, -0.027266579, 0.7933988...  \n3  [-0.32578343, 0.1525703, -0.5328208, -0.234771...  \n4  [0.068843156, 1.147965, 0.20798425, 0.16376394...  \n\n[5 rows x 56 columns]\n\nX_test_full head:\n   Tahun Permohonan  Kode_Kelas_1.0  Kode_Kelas_2.0  Kode_Kelas_3.0  \\\n0              2021           False           False           False   \n1              2018           False           False           False   \n2              2019           False           False            True   \n3              2022           False           False            True   \n4              2022           False           False           False   \n\n   Kode_Kelas_4.0  Kode_Kelas_5.0  Kode_Kelas_6.0  Kode_Kelas_7.0  \\\n0           False           False           False           False   \n1           False           False           False           False   \n2           False           False           False           False   \n3           False           False           False           False   \n4           False           False           False           False   \n\n   Kode_Kelas_8.0  Kode_Kelas_9.0  ...  Kode_Kelas_99.0                Brand  \\\n0           False           False  ...            False        itronics logo   \n1           False           False  ...            False         soto cak sun   \n2           False           False  ...            False  basic beauty center   \n3           False           False  ...            False        royal perfume   \n4           False            True  ...            False           richie tec   \n\n                      Logo File  Status_Encoded  \\\n0  logos_2021/DID2021024604.jpg               1   \n1  logos_2018/JID2018067513.jpg               1   \n2  logos_2019/DID2019035107.jpg               0   \n3  logos_2022/DID2022040342.jpg               0   \n4  logos_2022/DID2022063286.jpg               1   \n\n                           Nama Pemilik  Nomor Permohonan  \\\n0                 ITRONICS CO., LIMITED     DID2021024604   \n1  PT. CITARASA PRIMA INDONESIA BERJAYA     JID2018067513   \n2                    BASIC ZIA UL HAQUE     DID2019035107   \n3                      Syarief AbuBakar     DID2022040342   \n4                                Andrew     DID2022063286   \n\n               Nama Pemilik_normalized  \\\n0                  itronics_co_limited   \n1  pt_citarasa_prima_indonesia_berjaya   \n2                   basic_zia_ul_haque   \n3                     syarief_abubakar   \n4                               andrew   \n\n                                  Brand_Owner_Group  Split_Type  \\\n0                 itronics logo_itronics_co_limited        test   \n1  soto cak sun_pt_citarasa_prima_indonesia_berjaya        test   \n2            basic beauty center_basic_zia_ul_haque        test   \n3                    royal perfume_syarief_abubakar        test   \n4                                 richie tec_andrew        test   \n\n                                     image_embedding  \n0  [-0.07362983, 0.15109274, 0.051803667, -0.7176...  \n1  [-0.06725397, 1.4964787, -0.8408514, 0.3412623...  \n2  [0.17959723, 1.0641915, -0.7662309, 0.03787237...  \n3  [-1.6219082, 1.2261014, -0.19277856, -0.252446...  \n4  [-0.29802436, 0.57479316, 0.4207228, -0.772795...  \n\n[5 rows x 56 columns]\n\nX_val_full head:\n   Tahun Permohonan  Kode_Kelas_1.0  Kode_Kelas_2.0  Kode_Kelas_3.0  \\\n0              2018           False           False           False   \n1              2021           False           False           False   \n2              2019           False           False           False   \n3              2018           False           False           False   \n4              2018           False           False           False   \n\n   Kode_Kelas_4.0  Kode_Kelas_5.0  Kode_Kelas_6.0  Kode_Kelas_7.0  \\\n0           False            True           False           False   \n1           False           False           False           False   \n2           False           False           False           False   \n3           False           False           False           False   \n4           False           False           False           False   \n\n   Kode_Kelas_8.0  Kode_Kelas_9.0  ...  Kode_Kelas_99.0            Brand  \\\n0           False           False  ...            False   pulle dan logo   \n1           False           False  ...            False       winederful   \n2           False           False  ...            False    tiga ikan mas   \n3           False           False  ...            False  declip dan logo   \n4           False           False  ...            False            l t j   \n\n                      Logo File  Status_Encoded  \\\n0  logos_2018/D002018066743.jpg               1   \n1  logos_2021/DID2021011954.jpg               0   \n2  logos_2019/D002019031794.jpg               0   \n3  logos_2018/D002018009500.jpg               1   \n4  logos_2018/J002018004048.jpg               1   \n\n                       Nama Pemilik  Nomor Permohonan  \\\n0                          Rahmanda     D002018066743   \n1                  Hardwood Pte Ltd     DID2021011954   \n2                           Mat AIi     D002019031794   \n3        PT. Sumber Bintang Perkasa     D002018009500   \n4  PT. PP PROPERTI JABABEKA RESIDEN     J002018004048   \n\n           Nama Pemilik_normalized                          Brand_Owner_Group  \\\n0                         rahmanda                    pulle dan logo_rahmanda   \n1                 hardwood_pte_ltd                winederful_hardwood_pte_ltd   \n2                          mat_aii                      tiga ikan mas_mat_aii   \n3        pt_sumber_bintang_perkasa  declip dan logo_pt_sumber_bintang_perkasa   \n4  pt_pp_properti_jababeka_residen      l t j_pt_pp_properti_jababeka_residen   \n\n   Split_Type                                    image_embedding  \n0  validation  [-0.53431123, 0.5021055, 0.55004674, -0.104084...  \n1  validation  [-0.3447869, 0.8466035, -0.3939054, 0.00878146...  \n2  validation  [0.1947181, 0.5332825, -0.094632596, -0.394021...  \n3  validation  [-0.04105766, 0.9903644, -0.41361603, 0.449680...  \n4  validation  [-0.2820792, 0.263043, 0.023508124, -1.4660693...  \n\n[5 rows x 56 columns]\n\nDimensi embedding untuk X_train_full: (1024,)\nDimensi embedding untuk X_test_full: (1024,)\nDimensi embedding untuk X_val_full: (1024,)\n\nProses embedding gambar selesai sepenuhnya.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"X_train_full[\"Logo File\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T15:59:38.747602Z","iopub.execute_input":"2025-07-09T15:59:38.748382Z","iopub.status.idle":"2025-07-09T15:59:38.756043Z","shell.execute_reply.started":"2025-07-09T15:59:38.748350Z","shell.execute_reply":"2025-07-09T15:59:38.755263Z"}},"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"0                                  NaN\n1                                  NaN\n2                                  NaN\n3                                  NaN\n4                                  NaN\n                      ...             \n215960    logos_2022\\DID2022097139.jpg\n215961                             NaN\n215962    logos_2023\\DID2023087985.jpg\n215963                             NaN\n215964                             NaN\nName: Logo File, Length: 215965, dtype: object"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"X_train_full[\"Logo File\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T16:12:30.715735Z","iopub.execute_input":"2025-07-09T16:12:30.716017Z","iopub.status.idle":"2025-07-09T16:12:30.723297Z","shell.execute_reply.started":"2025-07-09T16:12:30.716000Z","shell.execute_reply":"2025-07-09T16:12:30.722371Z"}},"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"0                                  NaN\n1                                  NaN\n2                                  NaN\n3                                  NaN\n4                                  NaN\n                      ...             \n215960    logos_2022/DID2022097139.jpg\n215961                             NaN\n215962    logos_2023/DID2023087985.jpg\n215963                             NaN\n215964                             NaN\nName: Logo File, Length: 215965, dtype: object"},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"image_embedding_df_train = pd.DataFrame(X_train_full['image_embedding'].tolist(),\n                                        index=X_train_full.index,\n                                        columns=[f'image_emb_{i}' for i in range(EMBEDDING_DIM)])\nX_train_full = pd.concat([X_train_full.drop(columns=['image_embedding']), image_embedding_df_train], axis=1)\n\nimage_embedding_df_val = pd.DataFrame(X_val_full['image_embedding'].tolist(),\n                                      index=X_val_full.index,\n                                      columns=[f'image_emb_{i}' for i in range(EMBEDDING_DIM)])\nX_val_full = pd.concat([X_val_full.drop(columns=['image_embedding']), image_embedding_df_val], axis=1)\n\nimage_embedding_df_test = pd.DataFrame(X_test_full['image_embedding'].tolist(),\n                                       index=X_test_full.index,\n                                       columns=[f'image_emb_{i}' for i in range(EMBEDDING_DIM)])\nX_test_full = pd.concat([X_test_full.drop(columns=['image_embedding']), image_embedding_df_test], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T03:05:56.393520Z","iopub.execute_input":"2025-07-10T03:05:56.393843Z","iopub.status.idle":"2025-07-10T03:06:32.689863Z","shell.execute_reply.started":"2025-07-10T03:05:56.393823Z","shell.execute_reply":"2025-07-10T03:06:32.689262Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"X_train_full.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T03:06:52.354026Z","iopub.execute_input":"2025-07-10T03:06:52.354605Z","iopub.status.idle":"2025-07-10T03:06:52.387874Z","shell.execute_reply.started":"2025-07-10T03:06:52.354579Z","shell.execute_reply":"2025-07-10T03:06:52.387242Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"   Tahun Permohonan  Kode_Kelas_1.0  Kode_Kelas_2.0  Kode_Kelas_3.0  \\\n0              2020           False           False            True   \n1              2022           False           False           False   \n2              2020           False           False            True   \n3              2022           False           False           False   \n4              2022           False           False           False   \n\n   Kode_Kelas_4.0  Kode_Kelas_5.0  Kode_Kelas_6.0  Kode_Kelas_7.0  \\\n0           False           False           False           False   \n1           False           False           False           False   \n2           False           False           False           False   \n3           False           False           False           False   \n4           False           False           False           False   \n\n   Kode_Kelas_8.0  Kode_Kelas_9.0  ...  image_emb_1014  image_emb_1015  \\\n0           False           False  ...       -1.229826        0.624757   \n1           False           False  ...       -0.020854        0.082379   \n2           False           False  ...        0.065700       -0.069431   \n3           False           False  ...        0.380857        0.961326   \n4           False           False  ...       -0.282770        0.118539   \n\n   image_emb_1016  image_emb_1017  image_emb_1018  image_emb_1019  \\\n0       -0.430322       -0.922956       -0.143356        0.457215   \n1       -0.017575       -0.632895       -0.892011        0.224940   \n2       -0.094849       -0.708691        0.476040        1.178918   \n3       -0.520698       -0.634850       -0.260119        0.412645   \n4       -0.246904       -0.170817       -0.148840        1.517612   \n\n   image_emb_1020  image_emb_1021  image_emb_1022  image_emb_1023  \n0       -0.278216       -0.888517        0.384389       -0.364729  \n1       -0.725501        0.077203       -0.230002       -0.413936  \n2       -0.662423       -0.568342        0.410446        0.074811  \n3       -0.221425        0.015563        0.603319       -0.927598  \n4        0.069682       -0.207063        0.121679       -0.528606  \n\n[5 rows x 1079 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tahun Permohonan</th>\n      <th>Kode_Kelas_1.0</th>\n      <th>Kode_Kelas_2.0</th>\n      <th>Kode_Kelas_3.0</th>\n      <th>Kode_Kelas_4.0</th>\n      <th>Kode_Kelas_5.0</th>\n      <th>Kode_Kelas_6.0</th>\n      <th>Kode_Kelas_7.0</th>\n      <th>Kode_Kelas_8.0</th>\n      <th>Kode_Kelas_9.0</th>\n      <th>...</th>\n      <th>image_emb_1014</th>\n      <th>image_emb_1015</th>\n      <th>image_emb_1016</th>\n      <th>image_emb_1017</th>\n      <th>image_emb_1018</th>\n      <th>image_emb_1019</th>\n      <th>image_emb_1020</th>\n      <th>image_emb_1021</th>\n      <th>image_emb_1022</th>\n      <th>image_emb_1023</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>-1.229826</td>\n      <td>0.624757</td>\n      <td>-0.430322</td>\n      <td>-0.922956</td>\n      <td>-0.143356</td>\n      <td>0.457215</td>\n      <td>-0.278216</td>\n      <td>-0.888517</td>\n      <td>0.384389</td>\n      <td>-0.364729</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2022</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>-0.020854</td>\n      <td>0.082379</td>\n      <td>-0.017575</td>\n      <td>-0.632895</td>\n      <td>-0.892011</td>\n      <td>0.224940</td>\n      <td>-0.725501</td>\n      <td>0.077203</td>\n      <td>-0.230002</td>\n      <td>-0.413936</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>0.065700</td>\n      <td>-0.069431</td>\n      <td>-0.094849</td>\n      <td>-0.708691</td>\n      <td>0.476040</td>\n      <td>1.178918</td>\n      <td>-0.662423</td>\n      <td>-0.568342</td>\n      <td>0.410446</td>\n      <td>0.074811</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2022</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>0.380857</td>\n      <td>0.961326</td>\n      <td>-0.520698</td>\n      <td>-0.634850</td>\n      <td>-0.260119</td>\n      <td>0.412645</td>\n      <td>-0.221425</td>\n      <td>0.015563</td>\n      <td>0.603319</td>\n      <td>-0.927598</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2022</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>-0.282770</td>\n      <td>0.118539</td>\n      <td>-0.246904</td>\n      <td>-0.170817</td>\n      <td>-0.148840</td>\n      <td>1.517612</td>\n      <td>0.069682</td>\n      <td>-0.207063</td>\n      <td>0.121679</td>\n      <td>-0.528606</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 1079 columns</p>\n</div>"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"import pandas as pd\nimport os\nfrom PIL import Image\nimport torch\nfrom transformers import AutoImageProcessor, AutoModel\nfrom tqdm.notebook import tqdm \nimport numpy as np\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport gc \nfrom sklearn.model_selection import StratifiedKFold \n\nbase_dir_ditolak = '/kaggle/input/dataset-pdki-aplikasi-merek/dataset_logo_pdki_Ditolak/'\nbase_dir_didaftar = '/kaggle/input/dataset-pdki-aplikasi-merek/dataset_logo_pdki_Didaftar/'\n\ny_train_full = X_train_full[\"Status_Encoded\"]\ny_val_full = X_val_full[\"Status_Encoded\"]\ny_test_full = X_test_full[\"Status_Encoded\"]\n\nimage_emb_cols = [f'image_emb_{i}' for i in range(EMBEDDING_DIM)]\nif not all(col in X_train_full.columns for col in image_emb_cols):\n    raise ValueError(f\"Kolom embeddings gambar dengan prefix 'image_emb_' tidak ditemukan di X_train_full. Pastikan embedding gambar sudah dihasilkan dan dipecah.\")\nif 'Tahun Permohonan' not in X_train_full.columns:\n    raise ValueError(\"Kolom 'Tahun Permohonan' tidak ditemukan di X_train_full.\")\nprint(f\"\\nDitemukan {len(image_emb_cols)} kolom Image Embeddings dengan prefix 'image_emb_'.\")\n\n\n\ndef calculate_enriched_similarity_feature_batched_image(target_df, reference_embeddings_np, reference_years_np, embedding_col_names, batch_size=2000):\n    \"\"\"\n    Menghitung fitur 'max_sim' dan 'year_of_max_sim' untuk DataFrame target dalam batch.\n    Disesuaikan untuk image embeddings yang sudah dipecah.\n    \"\"\"\n    if reference_embeddings_np.shape[0] == 0:\n        \n        return np.zeros(target_df.shape[0], dtype=np.float32), np.full(target_df.shape[0], -1, dtype=np.int32) \n\n    all_max_similarities = []\n    all_years_of_max_similarities = []\n    \n    target_image_embeddings_np_full = target_df[embedding_col_names].values\n    target_years_np_full = target_df['Tahun Permohonan'].values\n\n    for i in tqdm(range(0, target_image_embeddings_np_full.shape[0], batch_size), desc=f\"Calculating Enriched Similarity for Image Embeddings\"):\n        batch_target_embeddings = target_image_embeddings_np_full[i : i + batch_size]\n        batch_target_years = target_years_np_full[i : i + batch_size]\n\n        similarities_batch = cosine_similarity(batch_target_embeddings, reference_embeddings_np)\n        \n        max_similarities_batch = np.max(similarities_batch, axis=1)\n        max_similarity_indices_batch = np.argmax(similarities_batch, axis=1)\n\n        years_of_max_similarities_batch = reference_years_np[max_similarity_indices_batch]\n\n        all_max_similarities.append(max_similarities_batch)\n        all_years_of_max_similarities.append(years_of_max_similarities_batch)\n        \n        del batch_target_embeddings, batch_target_years, similarities_batch, max_similarities_batch, max_similarity_indices_batch, years_of_max_similarities_batch\n        gc.collect()\n\n    return np.concatenate(all_max_similarities).astype(np.float32), np.concatenate(all_years_of_max_similarities).astype(np.int32)\n\n\ndef calculate_oof_similarity_features_image(X_train_df, y_train_series, embedding_col_names, n_splits=5, random_state=42, batch_size=2000):\n    \"\"\"\n    Menghitung fitur kemiripan (Rejected dan Registered) untuk X_train_df menggunakan OOF.\n    Disesuaikan untuk image embeddings yang sudah dipecah.\n    \"\"\"\n    print(f\"\\nMenghitung OOF similarity features untuk X_train_df dengan {n_splits}-fold CV (Image Embeddings)...\")\n\n    oof_max_sim_rej = np.zeros(len(X_train_df), dtype=np.float32)\n    oof_year_sim_rej = np.zeros(len(X_train_df), dtype=np.int32)\n    oof_max_sim_reg = np.zeros(len(X_train_df), dtype=np.float32)\n    oof_year_sim_reg = np.zeros(len(X_train_df), dtype=np.int32)\n\n    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n\n    for fold, (train_idx, val_idx) in tqdm(enumerate(skf.split(X_train_df, y_train_series)), total=n_splits, desc=\"OOF Folds (Image)\"):\n        X_fold_train = X_train_df.iloc[train_idx]\n        y_fold_train = y_train_series.iloc[train_idx]\n        X_fold_val = X_train_df.iloc[val_idx]\n\n        rejected_fold_train_indices = y_fold_train[y_fold_train == 0].index\n        rejected_emb_fold_train = X_fold_train.loc[rejected_fold_train_indices, embedding_col_names].values\n        rejected_years_fold_train = X_fold_train.loc[rejected_fold_train_indices, 'Tahun Permohonan'].values\n\n        registered_fold_train_indices = y_fold_train[y_fold_train == 1].index\n        registered_emb_fold_train = X_fold_train.loc[registered_fold_train_indices, embedding_col_names].values\n        registered_years_fold_train = X_fold_train.loc[registered_fold_train_indices, 'Tahun Permohonan'].values\n\n        max_sim_val_rej, year_sim_val_rej = calculate_enriched_similarity_feature_batched_image(\n            X_fold_val, rejected_emb_fold_train, rejected_years_fold_train, embedding_col_names, batch_size=batch_size\n        )\n        max_sim_val_reg, year_sim_val_reg = calculate_enriched_similarity_feature_batched_image(\n            X_fold_val, registered_emb_fold_train, registered_years_fold_train, embedding_col_names, batch_size=batch_size\n        )\n        \n        oof_max_sim_rej[val_idx] = max_sim_val_rej\n        oof_year_sim_rej[val_idx] = year_sim_val_rej\n        oof_max_sim_reg[val_idx] = max_sim_val_reg\n        oof_year_sim_reg[val_idx] = year_sim_val_reg\n        \n        del X_fold_train, y_fold_train, X_fold_val, rejected_emb_fold_train, rejected_years_fold_train, \\\n            registered_emb_fold_train, registered_years_fold_train, max_sim_val_rej, year_sim_val_rej, \\\n            max_sim_val_reg, year_sim_val_reg\n        gc.collect()\n\n    return oof_max_sim_rej, oof_year_sim_rej, oof_max_sim_reg, oof_year_sim_reg\n\nBATCH_SIZE_COSINE_SIM = 2000 \nN_SPLITS_OOF = 5 \n\noof_max_sim_rej_img, oof_year_sim_rej_img, oof_max_sim_reg_img, oof_year_sim_reg_img = calculate_oof_similarity_features_image(\n    X_train_full, y_train_full, image_emb_cols, n_splits=N_SPLITS_OOF, random_state=42, batch_size=BATCH_SIZE_COSINE_SIM\n)\nX_train_full['max_sim_to_rejected_logo_train'] = oof_max_sim_rej_img\nX_train_full['year_of_most_sim_rejected_logo_train'] = oof_year_sim_rej_img\nX_train_full['max_sim_to_registered_logo_train'] = oof_max_sim_reg_img\nX_train_full['year_of_most_sim_registered_logo_train'] = oof_year_sim_reg_img\n\nX_train_full['year_gap_to_most_sim_rejected_logo'] = X_train_full['Tahun Permohonan'] - X_train_full['year_of_most_sim_rejected_logo_train']\nX_train_full['year_gap_to_most_sim_registered_logo'] = X_train_full['Tahun Permohonan'] - X_train_full['year_of_most_sim_registered_logo_train']\n\nrejected_train_indices_global = y_train_full[y_train_full == 0].index\nregistered_train_indices_global = y_train_full[y_train_full == 1].index\n\nrejected_logo_embeddings_train_global = X_train_full.loc[rejected_train_indices_global, image_emb_cols].values\nrejected_logo_years_train_global = X_train_full.loc[rejected_train_indices_global, 'Tahun Permohonan'].values\n\nregistered_logo_embeddings_train_global = X_train_full.loc[registered_train_indices_global, image_emb_cols].values\nregistered_logo_years_train_global = X_train_full.loc[registered_train_indices_global, 'Tahun Permohonan'].values\n\nprint(f\"\\nJumlah sampel 'Ditolak' di set pelatihan global untuk referensi (Logo): {rejected_logo_embeddings_train_global.shape[0]}\")\nprint(f\"Jumlah sampel 'Didaftar' di set pelatihan global untuk referensi (Logo): {registered_logo_embeddings_train_global.shape[0]}\")\n\nprint(\"\\nMenghitung fitur kemiripan untuk X_val_full (Image Embeddings)...\")\nmax_sim_val_rej_img, year_sim_val_rej_img = calculate_enriched_similarity_feature_batched_image(\n    X_val_full, rejected_logo_embeddings_train_global, rejected_logo_years_train_global, image_emb_cols, batch_size=BATCH_SIZE_COSINE_SIM\n)\nX_val_full['max_sim_to_rejected_logo_train'] = max_sim_val_rej_img\nX_val_full['year_of_most_sim_rejected_logo_train'] = year_sim_val_rej_img\nX_val_full['year_gap_to_most_sim_rejected_logo'] = X_val_full['Tahun Permohonan'] - X_val_full['year_of_most_sim_rejected_logo_train']\n\nmax_sim_reg_val_img, year_sim_reg_val_img = calculate_enriched_similarity_feature_batched_image(\n    X_val_full, registered_logo_embeddings_train_global, registered_logo_years_train_global, image_emb_cols, batch_size=BATCH_SIZE_COSINE_SIM\n)\nX_val_full['max_sim_to_registered_logo_train'] = max_sim_reg_val_img\nX_val_full['year_of_most_sim_registered_logo_train'] = year_sim_reg_val_img\nX_val_full['year_gap_to_most_sim_registered_logo'] = X_val_full['Tahun Permohonan'] - X_val_full['year_of_most_sim_registered_logo_train']\n\nprint(\"\\nMenghitung fitur kemiripan untuk X_test_full (Image Embeddings)...\")\nmax_sim_test_rej_img, year_sim_test_rej_img = calculate_enriched_similarity_feature_batched_image(\n    X_test_full, rejected_logo_embeddings_train_global, rejected_logo_years_train_global, image_emb_cols, batch_size=BATCH_SIZE_COSINE_SIM\n)\nX_test_full['max_sim_to_rejected_logo_train'] = max_sim_test_rej_img\nX_test_full['year_of_most_sim_rejected_logo_train'] = year_sim_test_rej_img\nX_test_full['year_gap_to_most_sim_rejected_logo'] = X_test_full['Tahun Permohonan'] - X_test_full['year_of_most_sim_rejected_logo_train']\n\nmax_sim_reg_test_img, year_sim_reg_test_img = calculate_enriched_similarity_feature_batched_image(\n    X_test_full, registered_logo_embeddings_train_global, registered_logo_years_train_global, image_emb_cols, batch_size=BATCH_SIZE_COSINE_SIM\n)\nX_test_full['max_sim_to_registered_logo_train'] = max_sim_reg_test_img\nX_test_full['year_of_most_sim_registered_logo_train'] = year_sim_reg_test_img\nX_test_full['year_gap_to_most_sim_registered_logo'] = X_test_full['Tahun Permohonan'] - X_test_full['year_of_most_sim_registered_logo_train']\n\n\nprint(\"\\nFitur kemiripan logo yang diperkaya berhasil ditambahkan ke X_train, X_val, dan X_test.\")\n\nprint(f\"\\nShape X_train dengan fitur kemiripan logo baru: {X_train_full.shape}\")\nprint(f\"Shape X_val dengan fitur kemiripan logo baru: {X_val_full.shape}\")\nprint(f\"Shape X_test dengan fitur kemiripan logo baru: {X_test_full.shape}\")\n\nprint(\"\\nX_train_full head with new image similarity features:\")\nprint(X_train_full[['Logo File', 'Tahun Permohonan', 'max_sim_to_rejected_logo_train', 'year_of_most_sim_rejected_logo_train', 'year_gap_to_most_sim_rejected_logo', 'max_sim_to_registered_logo_train', 'year_of_most_sim_registered_logo_train', 'year_gap_to_most_sim_registered_logo']].head())\n\nprint(\"\\nX_val_full head with new image similarity features:\")\nprint(X_val_full[['Logo File', 'Tahun Permohonan', 'max_sim_to_rejected_logo_train', 'year_of_most_sim_rejected_logo_train', 'year_gap_to_most_sim_rejected_logo', 'max_sim_to_registered_logo_train', 'year_of_most_sim_registered_logo_train', 'year_gap_to_most_sim_registered_logo']].head())\n\nprint(\"\\nX_test_full head with new image similarity features:\")\nprint(X_test_full[['Logo File', 'Tahun Permohonan', 'max_sim_to_rejected_logo_train', 'year_of_most_sim_rejected_logo_train', 'year_gap_to_most_sim_rejected_logo', 'max_sim_to_registered_logo_train', 'year_of_most_sim_registered_logo_train', 'year_gap_to_most_sim_registered_logo']].head())\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T03:12:43.730872Z","iopub.execute_input":"2025-07-10T03:12:43.731593Z","iopub.status.idle":"2025-07-10T03:14:14.917897Z","shell.execute_reply.started":"2025-07-10T03:12:43.731561Z","shell.execute_reply":"2025-07-10T03:14:14.917085Z"}},"outputs":[{"name":"stdout","text":"\nDitemukan 1024 kolom Image Embeddings dengan prefix 'image_emb_'.\n\nMenghitung OOF similarity features untuk X_train_df dengan 5-fold CV (Image Embeddings)...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"OOF Folds (Image):   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6b765190c5849d581109a2a575dfb3a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Enriched Similarity for Image Embeddings:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b27316112f494963b90e98e8e00f14f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Enriched Similarity for Image Embeddings:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47d4ab68071b414eb1e2331813fc5b8a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Enriched Similarity for Image Embeddings:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28c224eac28c49feb36ddbfe1438327d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Enriched Similarity for Image Embeddings:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80801e47e4554c30aef52ba079ae6e0c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Enriched Similarity for Image Embeddings:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4033def02e304d458c1350408600153d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Enriched Similarity for Image Embeddings:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83b7163000d140bbb3d7d1f27dfec8dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Enriched Similarity for Image Embeddings:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c10f3ae61aad4985bd735a1a52ff7790"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Enriched Similarity for Image Embeddings:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e2e96fd1034494bb56736b0f783f376"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Enriched Similarity for Image Embeddings:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a978427393540369fa49a2921918443"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Enriched Similarity for Image Embeddings:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a562570289a470fbb6adb5d7e2e4c64"}},"metadata":{}},{"name":"stdout","text":"\nJumlah sampel 'Ditolak' di set pelatihan global untuk referensi (Logo): 9114\nJumlah sampel 'Didaftar' di set pelatihan global untuk referensi (Logo): 43675\n\nMenghitung fitur kemiripan untuk X_val_full (Image Embeddings)...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Calculating Enriched Similarity for Image Embeddings:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f9163c7982247f08bed9b7cf1616f3a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Enriched Similarity for Image Embeddings:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4dabaf9926884216a1f36058b680c3ee"}},"metadata":{}},{"name":"stdout","text":"\nMenghitung fitur kemiripan untuk X_test_full (Image Embeddings)...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Calculating Enriched Similarity for Image Embeddings:   0%|          | 0/9 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4468e7184eb74c4ba7aa336d9a34463f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Enriched Similarity for Image Embeddings:   0%|          | 0/9 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d65dd706d08495c9e24618886010744"}},"metadata":{}},{"name":"stdout","text":"\nFitur kemiripan logo yang diperkaya berhasil ditambahkan ke X_train, X_val, dan X_test.\n\nShape X_train dengan fitur kemiripan logo baru: (52789, 1085)\nShape X_val dengan fitur kemiripan logo baru: (13134, 1085)\nShape X_test dengan fitur kemiripan logo baru: (16160, 1085)\n\nX_train_full head with new image similarity features:\n                      Logo File  Tahun Permohonan  \\\n0  logos_2020/DID2020008379.jpg              2020   \n1  logos_2022/JID2022024980.jpg              2022   \n2  logos_2020/DID2020069641.jpg              2020   \n3  logos_2022/JID2022015471.jpg              2022   \n4  logos_2022/JID2022052066.jpg              2022   \n\n   max_sim_to_rejected_logo_train  year_of_most_sim_rejected_logo_train  \\\n0                        0.688583                                  2023   \n1                        0.684021                                  2023   \n2                        0.734442                                  2022   \n3                        0.652645                                  2024   \n4                        1.000000                                  2022   \n\n   year_gap_to_most_sim_rejected_logo  max_sim_to_registered_logo_train  \\\n0                                  -3                          0.999875   \n1                                  -1                          0.748459   \n2                                  -2                          0.742968   \n3                                  -2                          0.705361   \n4                                   0                          0.870600   \n\n   year_of_most_sim_registered_logo_train  \\\n0                                    2020   \n1                                    2021   \n2                                    2022   \n3                                    2021   \n4                                    2020   \n\n   year_gap_to_most_sim_registered_logo  \n0                                     0  \n1                                     1  \n2                                    -2  \n3                                     1  \n4                                     2  \n\nX_val_full head with new image similarity features:\n                      Logo File  Tahun Permohonan  \\\n0  logos_2018/D002018066743.jpg              2018   \n1  logos_2021/DID2021011954.jpg              2021   \n2  logos_2019/D002019031794.jpg              2019   \n3  logos_2018/D002018009500.jpg              2018   \n4  logos_2018/J002018004048.jpg              2018   \n\n   max_sim_to_rejected_logo_train  year_of_most_sim_rejected_logo_train  \\\n0                        0.612156                                  2019   \n1                        0.758385                                  2020   \n2                        0.579007                                  2019   \n3                        0.673458                                  2019   \n4                        0.605530                                  2019   \n\n   year_gap_to_most_sim_rejected_logo  max_sim_to_registered_logo_train  \\\n0                                  -1                          0.710984   \n1                                   1                          0.796158   \n2                                   0                          0.550211   \n3                                  -1                          0.686911   \n4                                  -1                          0.657351   \n\n   year_of_most_sim_registered_logo_train  \\\n0                                    2024   \n1                                    2023   \n2                                    2018   \n3                                    2024   \n4                                    2018   \n\n   year_gap_to_most_sim_registered_logo  \n0                                    -6  \n1                                    -2  \n2                                     1  \n3                                    -6  \n4                                     0  \n\nX_test_full head with new image similarity features:\n                      Logo File  Tahun Permohonan  \\\n0  logos_2021/DID2021024604.jpg              2021   \n1  logos_2018/JID2018067513.jpg              2018   \n2  logos_2019/DID2019035107.jpg              2019   \n3  logos_2022/DID2022040342.jpg              2022   \n4  logos_2022/DID2022063286.jpg              2022   \n\n   max_sim_to_rejected_logo_train  year_of_most_sim_rejected_logo_train  \\\n0                        0.892315                                  2022   \n1                        0.766893                                  2023   \n2                        0.720593                                  2023   \n3                        0.683339                                  2021   \n4                        0.686139                                  2024   \n\n   year_gap_to_most_sim_rejected_logo  max_sim_to_registered_logo_train  \\\n0                                  -1                          0.944889   \n1                                  -5                          0.769579   \n2                                  -4                          0.781118   \n3                                   1                          0.726728   \n4                                  -2                          0.785863   \n\n   year_of_most_sim_registered_logo_train  \\\n0                                    2019   \n1                                    2020   \n2                                    2024   \n3                                    2022   \n4                                    2023   \n\n   year_gap_to_most_sim_registered_logo  \n0                                     2  \n1                                    -2  \n2                                    -5  \n3                                     0  \n4                                    -1  \n","output_type":"stream"}],"execution_count":16}]}